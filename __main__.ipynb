{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T02:58:39.372904Z",
     "iopub.status.busy": "2022-07-06T02:58:39.372206Z",
     "iopub.status.idle": "2022-07-06T02:59:28.631038Z",
     "shell.execute_reply": "2022-07-06T02:59:28.629921Z",
     "shell.execute_reply.started": "2022-07-06T02:58:39.372861Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting lifelines==0.27.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8f/f6/56817d77b6a825604bf4eed0a27995a77a6ba3ee5f57d6baa1aacf77d62b/lifelines-0.27.0-py3-none-any.whl (349 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.1/349.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from lifelines==0.27.0) (1.20.3)\n",
      "Collecting matplotlib>=3.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/e7/0ad4aad00d6d0314aaf97526a54a34d385f898ebb7915d112431fff452ff/matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from lifelines==0.27.0) (1.6.3)\n",
      "Collecting autograd>=1.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d9/6e/5aec16d68bf07e17e1a6cac5011e1c8f5f8dadb0ac5e875d432ee8aaa733/autograd-1.4-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting formulaic>=0.2.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1a/ae/c3ce1d2935abddef895fd6b0e4f1a06c8d5ff92f6f7ed87861f6e1616df2/formulaic-0.3.4-py3-none-any.whl (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autograd-gamma>=0.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/85/ae/7f2031ea76140444b2453fa139041e5afd4a09fc5300cfefeb1103291f80/autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from lifelines==0.27.0) (1.1.5)\n",
      "Requirement already satisfied: future>=0.15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from autograd>=1.3->lifelines==0.27.0) (0.18.0)\n",
      "Collecting interface-meta<2.0.0,>=1.2.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/02/3f/a6ec28c88e2d8e54d32598a1e0b5208a4baa72a8e7f6e241beab5731eb9d/interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: wrapt>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from formulaic>=0.2.2->lifelines==0.27.0) (1.12.1)\n",
      "Collecting pandas>=1.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3e/0c/23764c4635dcb0a784a787498d56847b90ebf974e65f4ab4053a5d97b1a5/pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: astor>=0.8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from formulaic>=0.2.2->lifelines==0.27.0) (0.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines==0.27.0) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines==0.27.0) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines==0.27.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines==0.27.0) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines==0.27.0) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2f/85/2f6e42fb4b537b9998835410578fb1973175b81691e9a82ab6668cf64b0b/fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.9/930.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines==0.27.0) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas>=1.0.0->lifelines==0.27.0) (2019.3)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=3.0->lifelines==0.27.0) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.0->lifelines==0.27.0) (56.2.0)\n",
      "Building wheels for collected packages: autograd-gamma\n",
      "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4034 sha256=c7eeef3cee8026b1d7f38e8bc980175f171391e5808d6407a52bb8f9919f47fd\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/ab/0b/5c/977e05dfabbeeb83fc49bdb43b17fbdf47a3dfc2913a4d4a27\n",
      "Successfully built autograd-gamma\n",
      "Installing collected packages: interface-meta, fonttools, autograd, pandas, matplotlib, autograd-gamma, formulaic, lifelines\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 2.2.3\n",
      "    Uninstalling matplotlib-2.2.3:\n",
      "      Successfully uninstalled matplotlib-2.2.3\n",
      "Successfully installed autograd-1.4 autograd-gamma-0.5.0 fonttools-4.33.3 formulaic-0.3.4 interface-meta-1.3.0 lifelines-0.27.0 matplotlib-3.5.2 pandas-1.3.5\n",
      "Using pip 22.1.2 from /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip (python 3.7)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "  Link requires a different Python (3.7.4 not in: '>=3.8'): https://pypi.tuna.tsinghua.edu.cn/packages/4d/aa/e7078569d20f45e8cf6512a24bf2945698f13a7975650773c01366ea96dc/pandas-1.4.0.tar.gz#sha256=cdd76254c7f0a1583bd4e4781fb450d0ebf392e10d3f12e92c95575942e37df5 (from https://pypi.tuna.tsinghua.edu.cn/simple/pandas/) (requires-python:>=3.8)\n",
      "  Link requires a different Python (3.7.4 not in: '>=3.8'): https://pypi.tuna.tsinghua.edu.cn/packages/29/e3/6bd596d81eaf9f5b35398fdac0c535efadd9bbf8d0f859739badf9f90c63/pandas-1.4.0rc0.tar.gz#sha256=c0d453fda0a87d51f5fe65c16a89b64f13a736f4f17c0202cfcff67e6b341a57 (from https://pypi.tuna.tsinghua.edu.cn/simple/pandas/) (requires-python:>=3.8)\n",
      "  Link requires a different Python (3.7.4 not in: '>=3.8'): https://pypi.tuna.tsinghua.edu.cn/packages/c4/eb/cfa96ba42695b3c28d4864a796d492f188471dd536df7e5e5e0c54b629a6/pandas-1.4.1.tar.gz#sha256=8db93ec98ac7cb5f8ac1420c10f5e3c43533153f253fe7fb6d891cf5aa2b80d2 (from https://pypi.tuna.tsinghua.edu.cn/simple/pandas/) (requires-python:>=3.8)\n",
      "  Link requires a different Python (3.7.4 not in: '>=3.8'): https://pypi.tuna.tsinghua.edu.cn/packages/5a/ac/b3b9aa2318de52e40c26ae7b9ce6d4e9d1bcdaf5da0899a691642117cf60/pandas-1.4.2.tar.gz#sha256=92bc1fc585f1463ca827b45535957815b7deb218c549b7c18402c322c7549a12 (from https://pypi.tuna.tsinghua.edu.cn/simple/pandas/) (requires-python:>=3.8)\n",
      "  Link requires a different Python (3.7.4 not in: '>=3.8'): https://pypi.tuna.tsinghua.edu.cn/packages/f4/00/2de395c769335956b8650f990ef2a15e860be83b544c408ff95713446329/pandas-1.4.3.tar.gz#sha256=2ff7788468e75917574f080cd4681b27e1a7bf36461fe968b49a87b5a54d007c (from https://pypi.tuna.tsinghua.edu.cn/simple/pandas/) (requires-python:>=3.8)\n",
      "Collecting pandas==1.2.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ff/bd/fb376f9fbad92b9a6efdbb30ff32c80f3cba1368689309cbb5566364af5c/pandas-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas==1.2.0) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas==1.2.0) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas==1.2.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.2.0) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas-1.3.5.dist-info/\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "Successfully installed pandas-1.2.0\n",
      "Using pip 22.1.2 from /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip (python 3.7)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting matplotlib==2.2.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/52/46/ff47fea8e5c528c497fc385c95887131c4319a3411814ba9a766b66a9367/matplotlib-2.2.3-cp37-cp37m-manylinux1_x86_64.whl (12.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib==2.2.3) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib==2.2.3) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib==2.2.3) (1.20.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib==2.2.3) (0.10.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib==2.2.3) (1.16.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib==2.2.3) (2019.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib==2.2.3) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib==2.2.3) (56.2.0)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.2\n",
      "    Uninstalling matplotlib-3.5.2:\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/__pycache__/pylab.cpython-37.pyc\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib-3.5.2-py3.7-nspkg.pth\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib-3.5.2.dist-info/\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/mpl_toolkits/axes_grid/\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/mpl_toolkits/axes_grid1/\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/mpl_toolkits/axisartist/\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/mpl_toolkits/mplot3d/\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/mpl_toolkits/tests/\n",
      "      Removing file or directory /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pylab.py\n",
      "      Successfully uninstalled matplotlib-3.5.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lifelines 0.27.0 requires matplotlib>=3.0, but you have matplotlib 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed matplotlib-2.2.3\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pgl\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6d/2d/8f3dd46371f4c02d71c2d41f2fe64a063a53bf232466df011fef399c16c8/pgl-2.2.3.post0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cython>=0.25.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (0.29)\n",
      "Collecting numpy<1.20.0,>=1.16.4\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/08/d6/a6aaa29fea945bc6c61d11f6e0697b325ff7446de5ffd62c2fa02f627048/numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, pgl\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "parl 1.4.1 requires pyzmq==18.1.1, but you have pyzmq 23.1.0 which is incompatible.\n",
      "lifelines 0.27.0 requires matplotlib>=3.0, but you have matplotlib 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.19.5 pgl-2.2.3.post0\n"
     ]
    }
   ],
   "source": [
    "! pip install -V lifelines==0.27.0\n",
    "! pip install -v pandas==1.2.0\n",
    "! pip install -v matplotlib==2.2.3\n",
    "! pip install pgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T03:14:12.310334Z",
     "iopub.status.busy": "2022-07-06T03:14:12.309594Z",
     "iopub.status.idle": "2022-07-06T03:14:12.373241Z",
     "shell.execute_reply": "2022-07-06T03:14:12.372503Z",
     "shell.execute_reply.started": "2022-07-06T03:14:12.310296Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "import pgl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from sklearn import cluster\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import check_random_state, check_symmetric\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.utils import median_survival_times\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "class MLP(nn.Layer):\n",
    "    def __init__(self, in_dim, out_dim, hid_dim):\n",
    "        # hid_dim should be a list\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.LayerList()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        # 1st layer\n",
    "        self.layers.append(nn.Linear(self.in_dim, self.hid_dim[0], weight_attr=nn.initializer.KaimingUniform()))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        # hidden layer\n",
    "        for i in range(len(self.hid_dim) - 1):\n",
    "            self.layers.append(nn.Linear(self.hid_dim[i], self.hid_dim[i+1], weight_attr=nn.initializer.KaimingUniform()))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        # last layer\n",
    "        self.out_layer = nn.Linear(self.hid_dim[-1], out_dim, weight_attr=nn.initializer.KaimingUniform())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = layer(h)\n",
    "        h = self.out_layer(h)\n",
    "        h = paddle.tanh_(h)\n",
    "        return h\n",
    "\n",
    "class AdoptiveSoftThreshold(nn.Layer):\n",
    "    def __init__(self, dim):\n",
    "        super(AdoptiveSoftThreshold, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.add_parameter(\"bias\", paddle.create_parameter(shape=[self.dim], dtype=\"float32\", attr=nn.initializer.Constant(value=0.0)))\n",
    "    \n",
    "    def forward(self, c):\n",
    "        return paddle.sign(c) * F.relu(paddle.abs(c) - self.bias)\n",
    "\n",
    "\n",
    "class SENet(nn.Layer):\n",
    "    def __init__(self, in_dim, out_dim, hid_dim):\n",
    "        super(SENet, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        # layers\n",
    "        self.query_net = MLP(in_dim=self.in_dim, out_dim=self.out_dim, hid_dim=self.hid_dim)\n",
    "        self.key_net = MLP(in_dim=self.in_dim, out_dim=self.out_dim, hid_dim=self.hid_dim)\n",
    "        self.threshold = AdoptiveSoftThreshold(1)\n",
    "        # hyparameters\n",
    "        self.shrink = 1.0 / out_dim\n",
    "\n",
    "    def query_embedding(self, query):\n",
    "        query_emb = self.query_net(query)\n",
    "        return query_emb\n",
    "    \n",
    "    def key_embedding(self, key):\n",
    "        key_emb = self.key_net(key)\n",
    "        return key_emb\n",
    "\n",
    "    def get_coef(self, query, keys):\n",
    "        c = self.threshold(paddle.mm(query, keys.T))\n",
    "        return self.shrink * c\n",
    "\n",
    "    def forward(self, x, others):\n",
    "        query = self.query_embedding(x)\n",
    "        key = self.key_embedding(others)\n",
    "        out = self.get_coef(query, key)\n",
    "        return out\n",
    "\n",
    "def make_graph(array, k=20):\n",
    "    feature = paddle.to_tensor(array, dtype=\"float32\")\n",
    "    _, idx = paddle.topk(feature, k)\n",
    "    idx = idx.numpy()\n",
    "    edges = list()\n",
    "    for i in range(idx.shape[0]):\n",
    "        for j in idx[i]:\n",
    "            edges.append((i, j))\n",
    "    g = pgl.Graph(edges = edges,\n",
    "                num_nodes = feature.shape[0],\n",
    "                node_feat = {'nfeat':feature.T})\n",
    "    return g.tensor(), feature\n",
    "\n",
    "def regularizer(c, lmbd=1.0):\n",
    "    return lmbd * paddle.sum(paddle.abs(c)) + (1.0 - lmbd) / 2.0 * paddle.sum(paddle.pow(c, 2))\n",
    "\n",
    "def p_normalize(x, p=2):\n",
    "    return x / (paddle.norm(x, p=p, axis=1, keepdim=True) + 1e-6)\n",
    "\n",
    "def get_knn_Aff(C_sparse_normalized, k=3, mode='symmetric'):\n",
    "    C_knn = kneighbors_graph(C_sparse_normalized, k, mode='connectivity', include_self=False, n_jobs=10)\n",
    "    if mode == 'symmetric':\n",
    "        Aff_knn = 0.5 * (C_knn + C_knn.T)\n",
    "    elif mode == 'reciprocal':\n",
    "        Aff_knn = C_knn.multiply(C_knn.T)\n",
    "    else:\n",
    "        raise Exception(\"Mode must be 'symmetric' or 'reciprocal'\")\n",
    "    return Aff_knn\n",
    "\n",
    "def spectral_clustering(affinity_matrix_, n_clusters, k, seed=1, n_init=20):\n",
    "    affinity_matrix_ = check_symmetric(affinity_matrix_)\n",
    "    random_state = check_random_state(seed)\n",
    "\n",
    "    laplacian = sparse.csgraph.laplacian(affinity_matrix_, normed=True)\n",
    "    _, vec = sparse.linalg.eigsh(sparse.identity(laplacian.shape[0]) - laplacian, \n",
    "                                 k=k, sigma=None, which='LA')\n",
    "    embedding = normalize(vec)\n",
    "    _, labels_, _ = cluster.k_means(embedding, n_clusters, \n",
    "                                         random_state=seed, n_init=n_init)\n",
    "    return labels_\n",
    "\n",
    "def get_sparse_rep(model, data, batch_size=10, chunk_size=100, non_zeros = 10000):\n",
    "    N, D = data.shape\n",
    "    non_zeros = min(N, non_zeros)\n",
    "    c = paddle.empty([batch_size, N])\n",
    "    if (N % batch_size != 0):\n",
    "        raise Exception(\"batch_size should be a factor of dataset size.\")\n",
    "    if (N % chunk_size != 0):\n",
    "        raise Exception(\"chunk_size should be a factor of dataset size.\")\n",
    "\n",
    "    val = list()\n",
    "    indicies = list()\n",
    "\n",
    "    with paddle.no_grad():\n",
    "        model.eval()\n",
    "        for i in range(data.shape[0] // batch_size):\n",
    "            chunk = data[i * batch_size:(i + 1) * batch_size].cuda()\n",
    "            q = model.query_embedding(chunk)                                                                                                                                                                 \n",
    "            for j in range(data.shape[0] // chunk_size):\n",
    "                chunk_samples = data[j * chunk_size: (j + 1) * chunk_size].cuda()\n",
    "                k = model.key_embedding(chunk_samples)   \n",
    "                coef = model.get_coef(q, k)\n",
    "                c[:, j * chunk_size:(j + 1) * chunk_size] = coef.cpu()\n",
    "            \n",
    "            # diag c reset to zero\n",
    "            rows = list(range(batch_size))\n",
    "            cols = [j + i * batch_size for j in rows]\n",
    "            c[rows, cols] = 0.0\n",
    "            tmp = paddle.zeros_like(c)\n",
    "            # sort\n",
    "            _, index = paddle.topk(paddle.abs(c), axis=1, k=non_zeros)\n",
    "            for line in range(index.shape[0]):\n",
    "                tmp[line] = c[line].gather(index[line])\n",
    "            # val.append(paddle.gather(c, index=index, axis=1).reshape([-1]).cpu().numpy())\n",
    "            val.append(tmp.reshape([-1]).cpu().numpy())\n",
    "            index = index.reshape([-1]).cpu().numpy()\n",
    "            indicies.append(index)\n",
    "\n",
    "    val = np.concatenate(val, axis=0)\n",
    "    indicies = np.concatenate(indicies, axis=0)\n",
    "    indptr = [non_zeros * i for i in range(N + 1)]\n",
    "    \n",
    "    C_sparse = sparse.csr_matrix((val, indicies, indptr), shape=[N, N])\n",
    "    return C_sparse\n",
    "    \n",
    "def lifeline_analysis(df, n_groups):\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure()\n",
    "    for group in range(n_groups):\n",
    "        idx = (df[\"label\"] == group)\n",
    "        kmf.fit(df['Survival'][idx], df['Death'][idx], label = group)\n",
    "        ax = kmf.plot()\n",
    "        treatment_median_confidence_interval_ = median_survival_times(kmf.confidence_interval_)\n",
    "\n",
    "def evaluate(senet, data, num_subspaces, spectral_dim, non_zeros=1000, n_neighbors=3,\n",
    "             batch_size=10000, chunk_size=10000, affinity='nearest_neighbor', knn_mode='symmetric'):\n",
    "    C_sparse = get_sparse_rep(model=senet, data=data, batch_size=batch_size,\n",
    "                              chunk_size=chunk_size, non_zeros=non_zeros)\n",
    "    C_sparse_normalized = normalize(C_sparse).astype(np.float32)\n",
    "    # plt.matshow(np.sort(np.abs(C_sparse_normalized.toarray())))\n",
    "    if affinity == 'symmetric':\n",
    "        Aff = 0.5 * (np.abs(C_sparse_normalized) + np.abs(C_sparse_normalized).T)\n",
    "    elif affinity == 'nearest_neighbor':\n",
    "        Aff = get_knn_Aff(C_sparse_normalized, k=n_neighbors, mode=knn_mode)\n",
    "    else:\n",
    "        raise Exception(\"affinity should be 'symmetric' or 'nearest_neighbor'\")\n",
    "    \n",
    "    preds = spectral_clustering(Aff, num_subspaces, spectral_dim)\n",
    "\n",
    "    return C_sparse_normalized, preds\n",
    "\n",
    "def load_data(path):\n",
    "    path = os.path.join(\"TCGA\", path)\n",
    "    exp = pd.read_csv(os.path.join(path, \"exp\"), sep = \" \")\n",
    "    methy = pd.read_csv(os.path.join(path, \"methy\"), sep = \" \")\n",
    "    mirna = pd.read_csv(os.path.join(path, \"mirna\"), sep = \" \")\n",
    "    survival = pd.read_csv(os.path.join(path, \"survival\"), sep = \"\\t\")\n",
    "    survival = survival.dropna(axis=0)\n",
    "    if len(survival[\"PatientID\"][0]) > len('tcga.16.1060'):\n",
    "        name_list = list()\n",
    "        survival[\"PatientID\"] = [re.sub(\"-\", \".\", x) for x in survival[\"PatientID\"].str.upper()]\n",
    "        for token in survival[\"PatientID\"]:\n",
    "            if token[-2] != \"0\":\n",
    "                survival.drop(survival[survival[\"PatientID\"] == token].index, inplace = True)\n",
    "                continue\n",
    "            name_list.append(token)\n",
    "            if token not in exp:\n",
    "                exp[token] = exp.mean(axis=1)\n",
    "            if token not in methy:\n",
    "                methy[token] = methy.mean(axis=1)\n",
    "            if token not in mirna:\n",
    "                mirna[token] = mirna.mean(axis=1)\n",
    "    else:\n",
    "        survival[\"PatientID\"] = [re.sub(\"-\", \".\", x) for x in survival[\"PatientID\"].str.upper() + \".01\"]\n",
    "        for token in survival[\"PatientID\"]:\n",
    "            if token not in exp:\n",
    "                exp[token] = exp.mean(axis=1)\n",
    "            if token not in methy:\n",
    "                methy[token] = methy.mean(axis=1)\n",
    "            if token not in mirna:\n",
    "                mirna[token] = mirna.mean(axis=1)\n",
    "        name_list = survival[\"PatientID\"]\n",
    "    exp = exp[name_list]\n",
    "    methy = methy[name_list]\n",
    "    mirna = mirna[name_list]\n",
    "\n",
    "    return [exp, methy, mirna, survival]\n",
    "\n",
    "def draw_coef(coefficient, pred, N, epoch):\n",
    "    pc = pd.DataFrame(np.abs(coefficient.toarray()))\n",
    "    pc = pc + pc.T\n",
    "    pc[\"label\"] = pred\n",
    "    pc = pc.sort_values(\"label\")\n",
    "    idx = pc.index\n",
    "    pc = pc[idx]\n",
    "    plt.pcolor(pc)\n",
    "    plt.savefig(os.path.join(\"/home/aistudio/.jupyter/lab/workspaces/figures\", str(N), str(epoch), \".png\"))\n",
    "    # plt.show()\n",
    "\n",
    "class GCN(nn.Layer):\n",
    "    \"\"\"Implement of GCN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 num_class,\n",
    "                 num_layers=3,\n",
    "                 hidden_size=256,\n",
    "                 **kwargs):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gcns = nn.LayerList()\n",
    "        for i in range(self.num_layers):\n",
    "            if i == 0:\n",
    "                self.gcns.append(\n",
    "                    pgl.nn.GCNConv(\n",
    "                        input_size,\n",
    "                        self.hidden_size,\n",
    "                        activation=\"relu\",\n",
    "                        norm=True))\n",
    "            else:\n",
    "                self.gcns.append(\n",
    "                    pgl.nn.GCNConv(\n",
    "                        self.hidden_size,\n",
    "                        self.hidden_size,\n",
    "                        activation=\"relu\",\n",
    "                        norm=True))\n",
    "        self.output = nn.Linear(self.hidden_size, self.num_class, weight_attr=nn.initializer.KaimingUniform())\n",
    "    def forward(self, graph, feature):\n",
    "        for m in self.gcns:\n",
    "            feature = m(graph, feature)\n",
    "        logits = self.output(feature)\n",
    "        return logits\n",
    "\n",
    "class Attention(nn.Layer):\n",
    "    def __init__(self, in_size, hidden_size=16):\n",
    "        super(Attention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = paddle.nn.functional.softmax(w, axis=1)\n",
    "        return (beta * z).sum(1), beta\n",
    "\n",
    "class SEGN(nn.Layer):\n",
    "    def __init__(self, in_dim, out_dim, hid_dim):\n",
    "        super(SEGN, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        # layers\n",
    "        self.special_emb_exp = GCN(input_size=self.in_dim, num_class=self.out_dim, hidden_size=self.hid_dim)\n",
    "        self.special_emb_methy = GCN(input_size=self.in_dim, num_class=self.out_dim, hidden_size=self.hid_dim)\n",
    "        self.special_emb_mirna = GCN(input_size=self.in_dim, num_class=self.out_dim, hidden_size=self.hid_dim)\n",
    "\n",
    "        self.common_emb = GCN(input_size=self.in_dim, num_class=self.out_dim, hidden_size=self.hid_dim)\n",
    "        self.threshold = AdoptiveSoftThreshold(1)\n",
    "\n",
    "        self.attention = Attention(out_dim, hidden_size=hid_dim)\n",
    "        # hyparameters\n",
    "        self.shrink = 1.0 / out_dim\n",
    "\n",
    "    def special_embedding(self, graphs, features):\n",
    "        emb_1 = self.special_emb_exp(graphs[0], features[0])\n",
    "        emb_2 = self.special_emb_methy(graphs[1], features[1])\n",
    "        emb_3 = self.special_emb_mirna(graphs[2], features[2])\n",
    "\n",
    "        return paddle.stack([emb_1, emb_2, emb_3], axis=1)\n",
    "    \n",
    "    def shared_embedding(self, graphs, features):\n",
    "        shared_emb = self.common_emb(graphs, features)\n",
    "        return shared_emb\n",
    "\n",
    "    def get_coef(self, query, keys):\n",
    "        c = self.threshold(paddle.mm(query, keys.T))\n",
    "        return self.shrink * c\n",
    "\n",
    "    def forward(self, graphs, features):\n",
    "        shared_1 = self.shared_embedding(graphs[0], features[0])\n",
    "        shared_2 = self.shared_embedding(graphs[1], features[1])\n",
    "        shared_3 = self.shared_embedding(graphs[2], features[2])\n",
    "        shared = (shared_1 + shared_2 + shared_3) / 3\n",
    "\n",
    "        special = self.special_embedding(graphs, features)\n",
    "        emb, att = self.attention(special)\n",
    "        out = self.get_coef(shared, emb)\n",
    "        return out, shared, emb, att\n",
    "\n",
    "def make_graph(array, k=20):\n",
    "    feature = paddle.to_tensor(array, dtype=\"float32\")\n",
    "    _, idx = paddle.topk(feature, k)\n",
    "    idx = idx.numpy()\n",
    "    edges = list()\n",
    "    for i in range(idx.shape[0]):\n",
    "        for j in idx[i]:\n",
    "            edges.append((i, j))\n",
    "    g = pgl.Graph(edges = edges,\n",
    "                num_nodes = feature.shape[0],\n",
    "                node_feat = {'nfeat':feature.T})\n",
    "    return g.tensor(), feature\n",
    "\n",
    "def g_evaluate(model, graphs, features, num_subspaces, spectral_dim, non_zeros=1000, n_neighbors=3,\n",
    "             batch_size=10000, chunk_size=10000, affinity='nearest_neighbor', knn_mode='symmetric'):\n",
    "    N, D = features[0].shape\n",
    "    non_zeros = min(N, non_zeros)\n",
    "    c = paddle.empty([batch_size, N])\n",
    "    val = list()\n",
    "    indicies = list()\n",
    "\n",
    "    with paddle.no_grad():\n",
    "        model.eval()\n",
    "        coef, shared, emb, att = g_ae(graphs, features)\n",
    "        c = coef.cpu()\n",
    "\n",
    "        rows = list(range(batch_size))\n",
    "        cols = [j for j in rows]\n",
    "        c[rows, cols] = 0.0\n",
    "        tmp = paddle.zeros_like(c)\n",
    "        # sort\n",
    "        _, index = paddle.topk(paddle.abs(c), axis=1, k=batch_size)\n",
    "        for line in range(index.shape[0]):\n",
    "            tmp[line] = c[line].gather(index[line])\n",
    "        # val.append(paddle.gather(c, index=index, axis=1).reshape([-1]).cpu().numpy())\n",
    "        val.append(tmp.reshape([-1]).cpu().numpy())\n",
    "        index = index.reshape([-1]).cpu().numpy()\n",
    "        indicies.append(index)\n",
    "    val = np.concatenate(val, axis=0)\n",
    "    indicies = np.concatenate(indicies, axis=0)\n",
    "    indptr = [non_zeros * i for i in range(N + 1)]\n",
    "    C_sparse = sparse.csr_matrix((val, indicies, indptr), shape=[N, N])\n",
    "    \n",
    "    C_sparse_normalized = normalize(C_sparse).astype(np.float32)\n",
    "    # plt.matshow(np.sort(np.abs(C_sparse_normalized.toarray())))\n",
    "    if affinity == 'symmetric':\n",
    "        Aff = 0.5 * (np.abs(C_sparse_normalized) + np.abs(C_sparse_normalized).T)\n",
    "    elif affinity == 'nearest_neighbor':\n",
    "        Aff = get_knn_Aff(C_sparse_normalized, k=n_neighbors, mode=knn_mode)\n",
    "    else:\n",
    "        raise Exception(\"affinity should be 'symmetric' or 'nearest_neighbor'\")\n",
    "    \n",
    "    preds = spectral_clustering(Aff, num_subspaces, spectral_dim)\n",
    "\n",
    "    return C_sparse_normalized, preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T02:59:29.902919Z",
     "iopub.status.busy": "2022-07-06T02:59:29.902378Z",
     "iopub.status.idle": "2022-07-06T02:59:53.935606Z",
     "shell.execute_reply": "2022-07-06T02:59:53.934686Z",
     "shell.execute_reply.started": "2022-07-06T02:59:29.902891Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cancer_type = \"coad\"\n",
    "[exp, methy, mirna, survival] = load_data(cancer_type)\n",
    "\n",
    "conf = dict()\n",
    "conf[\"dataset\"] = cancer_type\n",
    "conf[\"chunk_size\"] = exp.shape[1]\n",
    "\n",
    "conf[\"batch_size\"] = 100\n",
    "conf[\"out_dim\"] = 512\n",
    "conf[\"hid_dim\"] = [1024, 1024]\n",
    "\n",
    "conf[\"learning_rate\"] = 1e-3\n",
    "conf[\"lmbd\"] = 0.1\n",
    "conf[\"gamma\"] = 50\n",
    "conf[\"min_lr\"] = 1e-4\n",
    "conf[\"total_iters\"] = 20000\n",
    "conf[\"save_iter\"] = 2000\n",
    "conf[\"eval_iter\"] = 500\n",
    "if conf[\"dataset\"] == \"bic\":\n",
    "    conf[\"subspace\"] = 5\n",
    "elif conf[\"dataset\"] == \"coad\":\n",
    "    conf[\"subspace\"] = 4\n",
    "elif conf[\"dataset\"] is \"gbm\":\n",
    "    conf[\"subspace\"] = 3\n",
    "elif conf[\"dataset\"] is \"kirc\":\n",
    "    conf[\"subspace\"] = 4\n",
    "elif conf[\"dataset\"] is \"ov\":\n",
    "    conf[\"subspace\"] = 3\n",
    "elif conf[\"dataset\"] is \"lusc\":\n",
    "    conf[\"subspace\"] = 5\n",
    "elif conf[\"dataset\"] is \"skcm\":\n",
    "    conf[\"subspace\"] = 5\n",
    "else:\n",
    "    pass\n",
    "conf[\"spectral_dim\"] = 15\n",
    "conf[\"non_zeros\"] = 10000\n",
    "conf[\"n_neighbors\"] = 3\n",
    "conf[\"affinity\"] = \"nearest_neighbor\"\n",
    "conf[\"g_lmbd\"] = 0.5\n",
    "conf[\"g_gamma\"] = 10\n",
    "conf[\"g_learning_rate\"] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T08:38:48.033418Z",
     "iopub.status.busy": "2022-06-11T08:38:48.032997Z",
     "iopub.status.idle": "2022-06-11T08:38:48.049915Z",
     "shell.execute_reply": "2022-06-11T08:38:48.049437Z",
     "shell.execute_reply.started": "2022-06-11T08:38:48.033389Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_process(data, conf, which):\n",
    "    row_data = paddle.to_tensor(data.to_numpy(), dtype=\"float32\")\n",
    "    # row_data shape [20531, 1229]\n",
    "    global_step = 0\n",
    "\n",
    "    folder = \"{}_result\".format(conf[\"dataset\"])\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    result = open(f'{folder}/{which}_results.csv', 'w+')\n",
    "    writer = csv.writer(result)\n",
    "    writer.writerow([\"-log(p)\", \"p\", \"iters\"])\n",
    "    for N in [200]:\n",
    "        block_size = min(N, 600)\n",
    "        sample_idx = np.random.choice(row_data.shape[1], N, replace=False)\n",
    "        data = row_data.T[sample_idx]\n",
    "        data = p_normalize(data)\n",
    "        sample_shape = data.shape\n",
    "        n_iter_per_epoch = data.shape[0] // conf[\"batch_size\"]\n",
    "        # data.shape [sampel, dim]\n",
    "        n_step_per_iter = round(data.shape[0] // block_size)\n",
    "        n_epochs = conf[\"total_iters\"] // n_iter_per_epoch\n",
    "        \n",
    "        local_senet = SENet(sample_shape[1], conf[\"out_dim\"], conf[\"hid_dim\"])\n",
    "\n",
    "        # para_dict = paddle.load(\"local_net.pdparams\")\n",
    "        # local_senet.load_dict(para_dict)\n",
    "        \n",
    "        clip = paddle.nn.ClipGradByGlobalNorm(clip_norm=0.001)\n",
    "        opt = paddle.optimizer.AdamW(learning_rate=conf[\"learning_rate\"], parameters=local_senet.parameters(), grad_clip=clip)\n",
    "        scheduler = paddle.optimizer.lr.CosineAnnealingDecay(conf[\"learning_rate\"], T_max=n_epochs, eta_min=conf[\"min_lr\"])\n",
    "\n",
    "        n_iter = 0\n",
    "        pbar = tqdm(range(n_epochs), ncols=120)\n",
    "        for epoch in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch}\")\n",
    "            randidx = paddle.randperm(sample_shape[0])\n",
    "            for i in range(n_iter_per_epoch):\n",
    "                # each batch in sample\n",
    "                local_senet.train()\n",
    "                batch_idx = randidx[i * conf[\"batch_size\"] : (i + 1) * conf[\"batch_size\"]]\n",
    "                batch = data[batch_idx]\n",
    "                # process all embedding of query and key\n",
    "                query_batch = local_senet.query_embedding(batch)\n",
    "                key_batch = local_senet.query_embedding(batch)\n",
    "\n",
    "                rec_batch = paddle.zeros_like(batch)\n",
    "                reg = paddle.zeros([1])\n",
    "                # each batch be reconstructed by sample\n",
    "                for j in range(n_step_per_iter):\n",
    "                    block = data[j * block_size: (j + 1) * block_size]\n",
    "                    key_block = local_senet.key_embedding(block)\n",
    "                    coef = local_senet.get_coef(query_batch, key_block)\n",
    "                    rec_batch = rec_batch + paddle.mm(coef, block)\n",
    "                    reg = reg + regularizer(coef, conf[\"lmbd\"])\n",
    "            \n",
    "                diag_c = local_senet.threshold((query_batch * key_batch).sum(axis=1, keepdim=True)) * local_senet.shrink\n",
    "                rec_batch = rec_batch - diag_c * batch\n",
    "                rec_loss = paddle.sum(paddle.pow(batch - rec_batch, 2))\n",
    "                loss = (0.5 * conf[\"gamma\"] * rec_loss + reg) / conf[\"batch_size\"]\n",
    "\n",
    "                opt.clear_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                global_step += 1\n",
    "                n_iter += 1\n",
    "\n",
    "                if n_iter % conf[\"save_iter\"] == 0:\n",
    "                    paddle.save(local_senet.state_dict(), f\"{folder}/{which}/{which}_{n_iter}_local.pdparams\")\n",
    "                    paddle.save(opt.state_dict(), \"opt.pdopt\")\n",
    "                    # print(\"Save Success.\")\n",
    "                \n",
    "                if n_iter % conf[\"eval_iter\"] == 0:\n",
    "                    # print(\"Evaluating on {}-full...\".format(conf[\"dataset\"]))\n",
    "                    full_data = p_normalize(row_data)\n",
    "                    coefficient, pred = evaluate(local_senet, data=full_data.T, num_subspaces=conf[\"subspace\"], affinity=conf[\"affinity\"],\n",
    "                                            spectral_dim=conf[\"spectral_dim\"], non_zeros=conf[\"non_zeros\"], n_neighbors=conf[\"n_neighbors\"], batch_size=conf[\"chunk_size\"],\n",
    "                                            chunk_size=conf[\"chunk_size\"], knn_mode='symmetric')\n",
    "                    survival[\"label\"] = pred\n",
    "                    df = survival\n",
    "                    # lifeline_analysis(df, conf[\"subspace\"])\n",
    "                    results = multivariate_logrank_test(df['Survival'], df['label'], df['Death'])\n",
    "                    if results.summary[\"p\"].item() < 7e-7:\n",
    "                        paddle.save(local_senet.state_dict(), f\"{folder}/{which}/{which}_{n_iter}_local.pdparams\")\n",
    "                    # print(\"-log2(p)-{:.6f}, p-{:.6f}\".format(results.summary[\"-log2(p)\"].item(), results.summary[\"p\"].item()))\n",
    "                    writer.writerow([results.summary[\"-log2(p)\"].item(), results.summary[\"p\"].item(), n_iter])\n",
    "                    # writer.writerow([results.summary[\"-log2(p)\"].item(), results.summary[\"p\"].item(), coefficient.toarray(), pred])\n",
    "                    result.flush()\n",
    "\n",
    "            pbar.set_postfix(loss=\"{:3.4f}\".format(loss.item()),\n",
    "                                rec_loss=\"{:3.4f}\".format(rec_loss.item() / conf[\"batch_size\"]),\n",
    "                                reg=\"{:3.4f}\".format(reg.item() / conf[\"batch_size\"]))\n",
    "            scheduler.step()\n",
    "    \n",
    "    return local_senet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T08:39:02.703419Z",
     "iopub.status.busy": "2022-06-11T08:39:02.702652Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 16:39:03.784927 38822 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0611 16:39:03.788691 38822 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "Epoch 1580:  16%|███▊                    | 1576/10000 [00:32<02:40, 52.52it/s, loss=3.1334, rec_loss=0.1133, reg=0.3017]"
     ]
    }
   ],
   "source": [
    "# start local train\n",
    "exp_net = train_process(exp, conf, \"exp\")\n",
    "methy_net = train_process(methy, conf, \"methy\")\n",
    "mirna_net = train_process(mirna, conf, \"mirna\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T03:34:11.142338Z",
     "iopub.status.busy": "2022-07-06T03:34:11.141617Z",
     "iopub.status.idle": "2022-07-06T03:34:11.164363Z",
     "shell.execute_reply": "2022-07-06T03:34:11.163270Z",
     "shell.execute_reply.started": "2022-07-06T03:34:11.142273Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature vis graph by pca\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_iris,load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def draw_coef(coefficient, pred, who, iters):\n",
    "    pc = pd.DataFrame(np.abs(coefficient.toarray()))\n",
    "    pc = pc + pc.T\n",
    "    pc[\"label\"] = pred\n",
    "    pc = pc.sort_values(\"label\")\n",
    "    idx = pc.index\n",
    "    pc = pc[idx]\n",
    "    plt.pcolor(pc)\n",
    "    plt.savefig(f\"figures/{who}/{iters}\")\n",
    "    # plt.show()\n",
    "\n",
    "def draw_coef_resutl(model, data, who):\n",
    "    for i in range(2000, 22000, 2000):\n",
    "        path = f\"bic_result/{who}/{who}_{str(i)}_local.pdparams\"\n",
    "        para_dict = paddle.load(path)\n",
    "        model.load_dict(para_dict)\n",
    "        c1, pred1 = evaluate(model, data=p_normalize(paddle.to_tensor(data.to_numpy().T, dtype=\"float32\")), num_subspaces=conf[\"subspace\"], affinity=conf[\"affinity\"],\n",
    "                                        spectral_dim=conf[\"spectral_dim\"], non_zeros=conf[\"non_zeros\"], n_neighbors=conf[\"n_neighbors\"], batch_size=conf[\"chunk_size\"],\n",
    "                                        chunk_size=conf[\"chunk_size\"], knn_mode='symmetric')\n",
    "        draw_coef(c1, pred1, str(who), str(i))\n",
    "        \n",
    "def lifeline_analysis(df, n_groups, title_g=\"bic\"):\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure()\n",
    "    for group in range(n_groups):\n",
    "        idx = (df[\"label\"] == group)\n",
    "        kmf.fit(df['Survival'][idx], df['Death'][idx], label = group)\n",
    "        plt.xlabel(\"lifeline(days)\")\n",
    "        plt.ylabel(\"survival probability\")\n",
    "        ax = kmf.plot()\n",
    "        plt.title(title_g)\n",
    "        treatment_median_confidence_interval_ = median_survival_times(kmf.confidence_interval_)\n",
    "# draw_coef_resutl(mirna_net, mirna, \"mirna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T03:32:03.187176Z",
     "iopub.status.busy": "2022-07-06T03:32:03.186503Z",
     "iopub.status.idle": "2022-07-06T03:32:03.553986Z",
     "shell.execute_reply": "2022-07-06T03:32:03.553036Z",
     "shell.execute_reply.started": "2022-07-06T03:32:03.187129Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "para_dict = paddle.load(\"coad_result/global/global_4000_local.pdparams\")\n",
    "g_ae.load_dict(para_dict)\n",
    "coef, shared, emb, att = g_ae([g1, g2, g3], [f1, f2,f3])\n",
    "coefficient, pred = g_evaluate(g_ae, [g1, g2, g3], [f1, f2,f3], num_subspaces=conf[\"subspace\"], affinity=conf[\"affinity\"],\n",
    "                                        spectral_dim=conf[\"spectral_dim\"], non_zeros=conf[\"non_zeros\"], n_neighbors=conf[\"n_neighbors\"], batch_size=conf[\"chunk_size\"],\n",
    "                                        chunk_size=conf[\"chunk_size\"], knn_mode='symmetric')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T03:34:27.818376Z",
     "iopub.status.busy": "2022-07-06T03:34:27.817730Z",
     "iopub.status.idle": "2022-07-06T03:34:34.022692Z",
     "shell.execute_reply": "2022-07-06T03:34:34.021830Z",
     "shell.execute_reply.started": "2022-07-06T03:34:27.818335Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_distr(coefficient, pred, gan, pred_gan, \"COAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T03:31:52.979785Z",
     "iopub.status.busy": "2022-07-06T03:31:52.979050Z",
     "iopub.status.idle": "2022-07-06T03:31:54.753053Z",
     "shell.execute_reply": "2022-07-06T03:31:54.751626Z",
     "shell.execute_reply.started": "2022-07-06T03:31:52.979742Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_net = SENet(exp.shape[0], conf[\"out_dim\"], conf[\"hid_dim\"])\n",
    "methy_net = SENet(methy.shape[0], conf[\"out_dim\"], conf[\"hid_dim\"])\n",
    "mirna_net = SENet(mirna.shape[0], conf[\"out_dim\"], conf[\"hid_dim\"])\n",
    "if conf[\"dataset\"] is \"bic\":\n",
    "    para_dict = paddle.load(\"bic_result/exp/exp_3000_local.pdparams\") \n",
    "    exp_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"bic_result/methy/methy_14000_local.pdparams\") \n",
    "    methy_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"bic_result/mirna/mirna_16000_local.pdparams\")\n",
    "    mirna_net.load_dict(para_dict)\n",
    "elif conf[\"dataset\"] is \"coad\":\n",
    "    para_dict = paddle.load(\"coad_result/exp/exp_20000_local.pdparams\") \n",
    "    exp_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"coad_result/methy/methy_16000_local.pdparams\") \n",
    "    methy_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"coad_result/mirna/mirna_16000_local.pdparams\")\n",
    "    mirna_net.load_dict(para_dict)\n",
    "elif conf[\"dataset\"] is \"gbm\":\n",
    "    para_dict = paddle.load(\"gbm_result/exp/exp_20000_local.pdparams\") \n",
    "    exp_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"gbm_result/methy/methy_20000_local.pdparams\") \n",
    "    methy_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"gbm_result/mirna/mirna_18000_local.pdparams\")\n",
    "    mirna_net.load_dict(para_dict)\n",
    "elif conf[\"dataset\"] is \"kirc\":\n",
    "    para_dict = paddle.load(\"kirc_result/exp/exp_7500_local.pdparams\") \n",
    "    exp_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"kirc_result/methy/methy_14000_local.pdparams\") \n",
    "    methy_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"kirc_result/mirna/mirna_16000_local.pdparams\")\n",
    "    mirna_net.load_dict(para_dict)\n",
    "elif conf[\"dataset\"] is \"lusc\":\n",
    "    para_dict = paddle.load(\"lusc_result/exp/exp_20000_local.pdparams\") \n",
    "    exp_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"lusc_result/methy/methy_20000_local.pdparams\") \n",
    "    methy_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"lusc_result/mirna/mirna_20000_local.pdparams\")\n",
    "    mirna_net.load_dict(para_dict)\n",
    "elif conf[\"dataset\"] is \"skcm\":\n",
    "    para_dict = paddle.load(\"lusc_result/exp/exp_4000_local.pdparams\") \n",
    "    exp_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"lusc_result/methy/methy_14000_local.pdparams\") \n",
    "    methy_net.load_dict(para_dict)\n",
    "    para_dict = paddle.load(\"lusc_result/mirna/mirna_16000_local.pdparams\")\n",
    "    mirna_net.load_dict(para_dict)\n",
    "c1, pred1 = evaluate(exp_net, data=p_normalize(paddle.to_tensor(exp.to_numpy().T, dtype=\"float32\")), num_subspaces=conf[\"subspace\"], affinity=conf[\"affinity\"],\n",
    "                                        spectral_dim=conf[\"spectral_dim\"], non_zeros=conf[\"non_zeros\"], n_neighbors=conf[\"n_neighbors\"], batch_size=conf[\"chunk_size\"],\n",
    "                                        chunk_size=conf[\"chunk_size\"], knn_mode='symmetric')\n",
    "c2, pred2 = evaluate(methy_net, data=p_normalize(paddle.to_tensor(methy.to_numpy().T, dtype=\"float32\")), num_subspaces=conf[\"subspace\"], affinity=conf[\"affinity\"],\n",
    "                                        spectral_dim=conf[\"spectral_dim\"], non_zeros=conf[\"non_zeros\"], n_neighbors=conf[\"n_neighbors\"], batch_size=conf[\"chunk_size\"],\n",
    "                                        chunk_size=conf[\"chunk_size\"], knn_mode='symmetric')\n",
    "c3, pred3 = evaluate(mirna_net, data=p_normalize(paddle.to_tensor(mirna.to_numpy().T, dtype=\"float32\")), num_subspaces=conf[\"subspace\"], affinity=conf[\"affinity\"],\n",
    "                                        spectral_dim=conf[\"spectral_dim\"], non_zeros=conf[\"non_zeros\"], n_neighbors=conf[\"n_neighbors\"], batch_size=conf[\"chunk_size\"],\n",
    "                                        chunk_size=conf[\"chunk_size\"], knn_mode='symmetric')\n",
    "if conf[\"dataset\"] is \"bic\":\n",
    "    # 4000\n",
    "    g1, f1 = make_graph(c1.toarray(), 12)\n",
    "    g2, f2 = make_graph(c2.toarray(), 12)\n",
    "    g3, f3 = make_graph(c3.toarray(), 12)\n",
    "elif conf[\"dataset\"] is \"coad\":\n",
    "    # 12000\n",
    "    g1, f1 = make_graph(c1.toarray(), 4)\n",
    "    g2, f2 = make_graph(c2.toarray(), 4)\n",
    "    g3, f3 = make_graph(c3.toarray(), 4)\n",
    "elif conf[\"dataset\"] is \"gbm\":\n",
    "    # 12000\n",
    "    g1, f1 = make_graph(c1.toarray(), 5)\n",
    "    g2, f2 = make_graph(c2.toarray(), 5)\n",
    "    g3, f3 = make_graph(c3.toarray(), 5)\n",
    "elif conf[\"dataset\"] is \"kirc\":\n",
    "    # 12000\n",
    "    g1, f1 = make_graph(c1.toarray(), 6)\n",
    "    g2, f2 = make_graph(c2.toarray(), 6)\n",
    "    g3, f3 = make_graph(c3.toarray(), 6)\n",
    "elif conf[\"dataset\"] is \"lusc\":\n",
    "    g1, f1 = make_graph(c1.toarray(), 6)\n",
    "    g2, f2 = make_graph(c2.toarray(), 5)\n",
    "    g3, f3 = make_graph(c3.toarray(), 5)\n",
    "elif conf[\"dataset\"] is \"kirc\":\n",
    "    g1, f1 = make_graph(c1.toarray(), 5)\n",
    "    g2, f2 = make_graph(c2.toarray(), 5)\n",
    "    g3, f3 = make_graph(c3.toarray(), 5)\n",
    "f1 = p_normalize(f1)\n",
    "f2 = p_normalize(f2)\n",
    "f3 = p_normalize(f3)\n",
    "g_dim = [f1.shape[0], f1.shape[0], 512]\n",
    "g_ae = SEGN(g_dim[0], g_dim[1], g_dim[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T09:47:55.141580Z",
     "iopub.status.busy": "2022-06-15T09:47:55.141352Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████▍                          | 17585/80000 [06:04<20:39, 50.36it/s, loss=22.6659, rec_loss=0.3898, reg=1.1943]"
     ]
    }
   ],
   "source": [
    "conf[\"g_lmbd\"] = 0.3\n",
    "conf[\"g_gamma\"] = 100\n",
    "conf[\"g_learning_rate\"] = 1e-3\n",
    "\n",
    "folder = \"{}_result\".format(conf[\"dataset\"])\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "result = open(f'{folder}/graph_results.csv', 'w+')\n",
    "writer = csv.writer(result)\n",
    "writer.writerow([\"-log(p)\", \"p\", \"iters\"])\n",
    "\n",
    "\n",
    "# get graph and normalized\n",
    "if conf[\"dataset\"] is \"bic\":\n",
    "    # 4000\n",
    "    g1, f1 = make_graph(c1.toarray(), 12)\n",
    "    g2, f2 = make_graph(c2.toarray(), 12)\n",
    "    g3, f3 = make_graph(c3.toarray(), 12)\n",
    "elif conf[\"dataset\"] is \"coad\":\n",
    "    # 12000\n",
    "    g1, f1 = make_graph(c1.toarray(), 4)\n",
    "    g2, f2 = make_graph(c2.toarray(), 4)\n",
    "    g3, f3 = make_graph(c3.toarray(), 4)\n",
    "elif conf[\"dataset\"] is \"gbm\":\n",
    "    # 12000\n",
    "    g1, f1 = make_graph(c1.toarray(), 5)\n",
    "    g2, f2 = make_graph(c2.toarray(), 5)\n",
    "    g3, f3 = make_graph(c3.toarray(), 5)\n",
    "elif conf[\"dataset\"] is \"kirc\":\n",
    "    # 12000\n",
    "    g1, f1 = make_graph(c1.toarray(), 6)\n",
    "    g2, f2 = make_graph(c2.toarray(), 6)\n",
    "    g3, f3 = make_graph(c3.toarray(), 6)\n",
    "elif conf[\"dataset\"] is \"lusc\":\n",
    "    g1, f1 = make_graph(c1.toarray(), 6)\n",
    "    g2, f2 = make_graph(c2.toarray(), 5)\n",
    "    g3, f3 = make_graph(c3.toarray(), 5)\n",
    "elif conf[\"dataset\"] is \"kirc\":\n",
    "    g1, f1 = make_graph(c1.toarray(), 5)\n",
    "    g2, f2 = make_graph(c2.toarray(), 5)\n",
    "    g3, f3 = make_graph(c3.toarray(), 5)\n",
    "f1 = p_normalize(f1)\n",
    "f2 = p_normalize(f2)\n",
    "f3 = p_normalize(f3)\n",
    "g_dim = [f1.shape[0], f1.shape[0], 512]\n",
    "g_ae = SEGN(g_dim[0], g_dim[1], g_dim[2])\n",
    "\n",
    "\n",
    "clip = paddle.nn.ClipGradByGlobalNorm(clip_norm=0.001)\n",
    "g_opt = paddle.optimizer.AdamW(learning_rate=conf[\"g_learning_rate\"], parameters=g_ae.parameters(), grad_clip=clip)\n",
    "pbar = tqdm(range(80000), ncols=120)\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "for epoch in pbar:\n",
    "    g_ae.train()\n",
    "    coef, shared, emb, att = g_ae([g1, g2, g3], [f1, f2,f3])\n",
    "    diag_c = g_ae.threshold((shared * emb).sum(axis=1, keepdim=True)) * g_ae.shrink\n",
    "    rec_g1 = paddle.mm(coef, f1) - diag_c * f1\n",
    "    rec_g2 = paddle.mm(coef, f2) - diag_c * f2\n",
    "    rec_g3 = paddle.mm(coef, f3) - diag_c * f3\n",
    "\n",
    "    reg = regularizer(coef, conf[\"g_lmbd\"])\n",
    "\n",
    "    g_loss1 = (0.5 * conf[\"g_gamma\"] * paddle.sum(paddle.pow(rec_g1 - f1, 2)) + reg) / f1.shape[0]\n",
    "    g_loss2 = (0.5 * conf[\"g_gamma\"] * paddle.sum(paddle.pow(rec_g2 - f2, 2)) + reg) / f1.shape[0]\n",
    "    g_loss3 = (0.5 * conf[\"g_gamma\"] * paddle.sum(paddle.pow(rec_g3 - f3, 2)) + reg) / f1.shape[0]\n",
    "\n",
    "    rec_loss = paddle.sum(paddle.pow(rec_g1 - f1, 2)) + paddle.sum(paddle.pow(rec_g2 - f2, 2)) + paddle.sum(paddle.pow(rec_g3 - f3, 2))\n",
    "    # loss = g_loss1 + g_loss2 + g_loss3\n",
    "    loss = (0.5 * conf[\"g_gamma\"] * rec_loss + reg) / f1.shape[0]\n",
    "\n",
    "    consis_loss = 0.1 * paddle.sum(paddle.pow(paddle.matmul(shared.T, shared) - paddle.matmul(emb.T, emb) ,2)) / f1.shape[0]\n",
    "    loss += consis_loss \n",
    "    # print(consis_loss.numpy())\n",
    "    # input()\n",
    "\n",
    "    g_opt.clear_grad()\n",
    "    loss.backward()\n",
    "    g_opt.step()\n",
    "    \n",
    "    n_iter += 1\n",
    "\n",
    "    if n_iter % conf[\"save_iter\"] == 0:\n",
    "        plt.figure()\n",
    "        paddle.save(g_ae.state_dict(), f\"{conf['dataset']}_result/global/global_{n_iter}_local.pdparams\")\n",
    "        paddle.save(g_opt.state_dict(), \"g_opt.pdopt\")\n",
    "        # att_pd = pd.DataFrame(att.squeeze(2).numpy())\n",
    "        # plt.boxplot(att_pd.values, labels=att_pd.columns)\n",
    "        # plt.show()\n",
    "        # print(\"Save Success.\")\n",
    "                \n",
    "    if n_iter % conf[\"eval_iter\"] == 0:\n",
    "        # print(\"Evaluating on {}-full...\".format(conf[\"dataset\"]))\n",
    "        coefficient, pred = g_evaluate(g_ae, [g1, g2, g3], [f1, f2,f3], num_subspaces=conf[\"subspace\"], affinity=conf[\"affinity\"],\n",
    "                                        spectral_dim=conf[\"spectral_dim\"], non_zeros=conf[\"non_zeros\"], n_neighbors=conf[\"n_neighbors\"], batch_size=conf[\"chunk_size\"],\n",
    "                                        chunk_size=conf[\"chunk_size\"], knn_mode='symmetric')\n",
    "        survival[\"label\"] = pred\n",
    "        df = survival\n",
    "        # lifeline_analysis(df, conf[\"subspace\"])\n",
    "        results = multivariate_logrank_test(df['Survival'], df['label'], df['Death'])\n",
    "        if results.summary[\"p\"].item() < 0.0003:\n",
    "             paddle.save(g_ae.state_dict(), f\"{conf['dataset']}_result/global/global_{n_iter}_local.pdparams\")\n",
    "        # print(\"-log2(p)-{:.6f}, p-{:.6f}\".format(results.summary[\"-log2(p)\"].item(), results.summary[\"p\"].item()))\n",
    "        writer.writerow([results.summary[\"-log2(p)\"].item(), results.summary[\"p\"].item(), n_iter])\n",
    "        # writer.writerow([results.summary[\"-log2(p)\"].item(), results.summary[\"p\"].item(), coefficient.toarray(), pred])\n",
    "        result.flush()\n",
    "\n",
    "    pbar.set_postfix(loss=\"{:3.4f}\".format(loss.item()),\n",
    "                                rec_loss=\"{:3.4f}\".format(rec_loss.item() / f1.shape[0]),\n",
    "                                reg=\"{:3.4f}\".format(reg.item() / f1.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T06:36:19.340113Z",
     "iopub.status.busy": "2022-06-12T06:36:19.339229Z",
     "iopub.status.idle": "2022-06-12T06:36:19.354896Z",
     "shell.execute_reply": "2022-06-12T06:36:19.354313Z",
     "shell.execute_reply.started": "2022-06-12T06:36:19.340070Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "which = \"bic\"\n",
    "exp = pd.read_csv(f\"{which}_result/exp_results.csv\")\n",
    "methy = pd.read_csv(f\"{which}_result/methy_results.csv\")\n",
    "mirna = pd.read_csv(f\"{which}_result/mirna_results.csv\")\n",
    "whole = pd.read_csv(f\"{which}_result/graph_results.csv\")\n",
    "tips =pd.concat([exp[\"-log(p)\"], methy[\"-log(p)\"], mirna[\"-log(p)\"], whole[\"-log(p)\"]], axis=1)\n",
    "tips.columns = [\"mRNA\", \"Methylation\", \"miRNA\", \"AM-SCM\"]\n",
    "tips[\"dataset\"] = which\n",
    "tips_list.append(tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T02:07:01.216112Z",
     "iopub.status.busy": "2022-04-16T02:07:01.215502Z",
     "iopub.status.idle": "2022-04-16T02:07:01.304143Z",
     "shell.execute_reply": "2022-04-16T02:07:01.303308Z",
     "shell.execute_reply.started": "2022-04-16T02:07:01.216072Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>null_distribution</th>\n",
       "      <td>chi squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degrees_of_freedom</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_name</th>\n",
       "      <td>multivariate_logrank_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_statistic</th>\n",
       "      <th>p</th>\n",
       "      <th>-log2(p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.80</td>\n",
       "      <td>0.07</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{tabular}{lrrr}\n",
       "\\toprule\n",
       "{} &  test\\_statistic &         p &  -log2(p) \\\\\n",
       "\\midrule\n",
       "0 &        8.804591 &  0.066174 &  3.917597 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<lifelines.StatisticalResult: multivariate_logrank_test>\n",
       "               t_0 = -1\n",
       " null_distribution = chi squared\n",
       "degrees_of_freedom = 4\n",
       "         test_name = multivariate_logrank_test\n",
       "\n",
       "---\n",
       " test_statistic    p  -log2(p)\n",
       "           8.80 0.07      3.92"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lifelines.datasets import load_waltons\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.utils import median_survival_times\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "\n",
    "test_pd = survival\n",
    "test_pd[\"label_1\"] = pred1\n",
    "test_pd[\"label_2\"] = pred2\n",
    "test_pd[\"label_3\"] = pred3\n",
    "\n",
    "df = test_pd\n",
    "results = multivariate_logrank_test(df['Survival'], df['label_2'], df['Death'])\n",
    "results.print_summary()\n",
    "\n",
    "# df = test_pd\n",
    "# ix = df['label_1'] == 0\n",
    "# T_exp, E_exp = df.loc[ix, 'Survival'], df.loc[ix, 'Death']\n",
    "# T_con, E_con = df.loc[~ix, 'Survival'], df.loc[~ix, 'Death']\n",
    "# results = logrank_test(T_exp, T_con, event_observed_A=E_exp, event_observed_B=E_con)\n",
    "# results.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_shape = train_data.data[0].shape\n",
    "model_header = LocalHeader()\n",
    "model_header.train()\n",
    "\n",
    "epoch = 2000\n",
    "learning_rate = 0.01\n",
    "opt = paddle.optimizer.Adam(learning_rate=learning_rate,parameters=model_header.parameters())\n",
    "\n",
    "x = paddle.to_tensor(train_data.data[0].to_numpy(), dtype=\"float32\").unsqueeze([0,1])\n",
    "\n",
    "for i in tqdm.tqdm(range(epoch)):\n",
    "    # input : ncl\n",
    "    x_reconstructed= model_header(x, True)\n",
    "    # express_loss = paddle.sum(paddle.pow(paddle.subtract(z, z_c), 2.0)) \n",
    "\n",
    "    # coefficient_loss = paddle.sum(paddle.pow(model_header.coefficient, 2)) /1299\n",
    "\n",
    "    # reconstruct_loss = paddle.sum(paddle.pow(paddle.subtract(x, x_reconstructed), 2.0)) / 1299\n",
    "    reconstruct_loss = paddle.nn.functional.mse_loss(input=x_reconstructed, label=x) \n",
    "\n",
    "    if i % 100 ==0:\n",
    "        print(reconstruct_loss)\n",
    "\n",
    "    loss =  reconstruct_loss\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.clear_grad()\n",
    "\n",
    "for i in tqdm.tqdm(range(epoch)):\n",
    "    # input : ncl\n",
    "    x_reconstructed, z, z_c = model_header(x, False)\n",
    "    express_loss = paddle.sum(paddle.pow(paddle.subtract(z, z_c), 2.0)) \n",
    "\n",
    "    # coefficient_loss = paddle.sum(paddle.pow(model_header.coefficient, 2)) /1299\n",
    "\n",
    "    # reconstruct_loss = paddle.sum(paddle.pow(paddle.subtract(x, x_reconstructed), 2.0)) / 1299\n",
    "    reconstruct_loss = paddle.nn.functional.mse_loss(input=x_reconstructed, label=x) \n",
    "\n",
    "    if i % 100 ==0:\n",
    "        print(reconstruct_loss, express_loss)\n",
    "\n",
    "    loss =  reconstruct_loss + express_loss / 12250\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.clear_grad()\n",
    "paddle.save(model_header.state_dict, \"AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "class LocalHeader(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LocalHeader, self).__init__()\n",
    "        # input NCHW\n",
    "        self.conv0 = nn.Conv2D(in_channels=1, out_channels=1, kernel_size=(5, 1))\n",
    "        self.conv1 = nn.Conv2D(in_channels=1, out_channels=1, kernel_size=(5, 1))\n",
    "        self.convT0 = nn.Conv2DTranspose(in_channels=1, out_channels=1, kernel_size=(5, 1))\n",
    "        self.convT1 = nn.Conv2DTranspose(in_channels=1, out_channels=1, kernel_size=(5, 1))\n",
    "\n",
    "        self.coefficient = paddle.create_parameter(shape=[1229, 1229], dtype='float32', default_initializer=paddle.nn.initializer.Uniform(low=0, high=1e-10))\n",
    "        self.add_parameter(\"coef\", self.coefficient)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, is_pretrain=True):\n",
    "        x = self.conv0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        if is_pretrain is False:\n",
    "            # self-expression start\n",
    "            x_shape = x.shape\n",
    "            x_value = x\n",
    "            x = paddle.reshape(x, [-1, 1229])\n",
    "            # x = paddle.matmul(x, self.coefficient - paddle.diag(self.coefficient, padding_value=0))\n",
    "            x = paddle.matmul(x, self.coefficient)\n",
    "            x = paddle.reshape(x, x_shape)\n",
    "            z_value = x\n",
    "            # self-expression end\n",
    "\n",
    "        x = self.convT0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.convT1(x)\n",
    "        x = F.relu(x)\n",
    "        if is_pretrain is False:\n",
    "            return x, x_value, z_value\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T06:58:14.494188Z",
     "iopub.status.busy": "2022-06-07T06:58:14.493915Z",
     "iopub.status.idle": "2022-06-07T06:58:14.511068Z",
     "shell.execute_reply": "2022-06-07T06:58:14.510491Z",
     "shell.execute_reply.started": "2022-06-07T06:58:14.494161Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "class SEGraphMaker(nn.Layer):\n",
    "    def __init__(self, num_sample, num_feature, num_cluster):\n",
    "        super(SEGraphMaker, self).__init__()\n",
    "        self.num_sample = num_sample\n",
    "        self.conv0 = paddle.nn.Conv1D(in_channels=1,out_channels=1,kernel_size=5,stride=1)\n",
    "        self.conv1 = paddle.nn.Conv1D(in_channels=1,out_channels=1,kernel_size=5,stride=1)\n",
    "        self.conv2 = paddle.nn.Conv1D(in_channels=1,out_channels=1,kernel_size=5,stride=1)\n",
    "\n",
    "        self.coefficient = paddle.create_parameter(shape=[num_sample, num_sample], dtype='float32', default_initializer=paddle.nn.initializer.Uniform(low=0, high=1e-10))\n",
    "        self.add_parameter(\"coef\", self.coefficient)\n",
    "\n",
    "        self.convT2 = paddle.nn.Conv1DTranspose(in_channels=1,out_channels=1,kernel_size=5,stride=1)\n",
    "        self.convT0 = paddle.nn.Conv1DTranspose(in_channels=1,out_channels=1,kernel_size=5,stride=1)\n",
    "        self.convT1 = paddle.nn.Conv1DTranspose(in_channels=1,out_channels=1,kernel_size=5,stride=1)\n",
    "        \n",
    "\n",
    "        self.bn_encoder = paddle.nn.BatchNorm(2)\n",
    "        self.bn_decoder = paddle.nn.BatchNorm(2)\n",
    "        # self.linear0 = paddle.nn.Linear(num_feature, 256)\n",
    "        # self.linear1 = paddle.nn.Linear(256, num_cluster)\n",
    "\n",
    "    def forward(self, x):\n",
    "        row_x = x\n",
    "        x = self.conv0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        z_reconstruct = self.convT2(x)\n",
    "        z_reconstruct = F.relu(z_reconstruct)\n",
    "        z_reconstruct = self.convT0(z_reconstruct)\n",
    "        z_reconstruct = F.relu(z_reconstruct)\n",
    "        z_reconstruct = self.convT1(z_reconstruct)\n",
    "        z_reconstruct = F.relu(z_reconstruct)\n",
    "\n",
    "        # label = self.linear0(z_reconstruct).squeeze(1)\n",
    "        # label = self.linear1(label)\n",
    "        # label = 0\n",
    "        return z_reconstruct\n",
    "\n",
    "\n",
    "    def thrC(self, C, ro):\n",
    "        C = C.numpy()\n",
    "        if ro < 1:\n",
    "            N = C.shape[1]\n",
    "            Cp = np.zeros((N,N))\n",
    "            S = np.abs(np.sort(-np.abs(C),axis=0))\n",
    "            Ind = np.argsort(-np.abs(C),axis=0)\n",
    "            for i in range(N):\n",
    "                cL1 = np.sum(S[:,i]).astype(float)\n",
    "                stop = False\n",
    "                csum = 0\n",
    "                t = 0\n",
    "                while(stop == False):\n",
    "                    csum = csum + S[t,i]\n",
    "                    if csum > ro*cL1:\n",
    "                        stop = True\n",
    "                        Cp[Ind[0:t+1,i],i] = C[Ind[0:t+1,i],i]\n",
    "                        # print(f\"cp:{Cp}\")\n",
    "                    t = t + 1\n",
    "        else:\n",
    "            Cp = C\n",
    "\n",
    "        return Cp\n",
    "\n",
    "    def post_proC(self, C, K, d, alpha):\n",
    "\n",
    "        # C: coefficient matrix, K: number of clusters, d: dimension of each subspace\n",
    "        C = 0.5*(C + C.T)\n",
    "        r = d*K + 1\n",
    "        U, S, _ = svds(C,r,v0 = np.ones(C.shape[0]))\n",
    "        U = U[:,::-1]    \n",
    "        S = np.sqrt(S[::-1])\n",
    "        S = np.diag(S)    \n",
    "        U = U.dot(S)\n",
    "        U = normalize(U, norm='l2', axis = 1)       \n",
    "        Z = U.dot(U.T)\n",
    "\n",
    "        Z = Z * (Z>0) \n",
    "\n",
    "        L = np.abs(Z ** alpha)\n",
    "        L = L/L.max()\n",
    "        L = 0.5 * (L + L.T)    \n",
    "\n",
    "        spectral = cluster.SpectralClustering(n_clusters=K, eigen_solver='arpack', affinity='precomputed',assign_labels='discretize')\n",
    "        spectral.fit(L)\n",
    "        grp = spectral.fit_predict(L)\n",
    "        return grp, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import tqdm\n",
    "import matplotlib.pyplot  as plt\n",
    "import work.dataloader_tcga as loader\n",
    "import work.model as model\n",
    "import work.graph_maker as maker\n",
    "import work.utils as utils\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# load dataset\n",
    "train_data = loader.TCGADataset(\"bic\", 64)\n",
    "\n",
    "# # get all views and graphs\n",
    "# view_graph = maker.similarityGraph(train_data)\n",
    "# view_origin = utils.parse_view_graph(view_graph)\n",
    "# # inite model\n",
    "# GAESC = model.myModel(1229, [20531, 5000, 1046])\n",
    "\n",
    "# # inite all loss function\n",
    "# ce_loss = paddle.nn.CrossEntropyLoss(reduction='mean', soft_label=True)\n",
    "# # ce_loss = paddle.nn.CrossEntropyLoss(soft_label=True)\n",
    "# mse_loss = paddle.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train part\n",
    "epoch_num = 500\n",
    "history_loss = []\n",
    "iter_epoch = []\n",
    "\n",
    "# GAESC.load_dict(paddle.load(\"model\"))\n",
    "GAESC.train()\n",
    "\n",
    "learning_rate = 0.01\n",
    "opt_AE = paddle.optimizer.Adam(learning_rate=learning_rate,parameters=GAESC.parameters())\n",
    "opt = paddle.optimizer.Adam(learning_rate=learning_rate,parameters=GAESC.parameters())\n",
    "\n",
    "\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    loss = 0\n",
    "    for index in range(len(view_origin)):\n",
    "        latent, expression = GAESC.train_AE(view_origin[index], index)\n",
    "        pred = paddle.nn.Sigmoid()(paddle.matmul(expression, expression.T))\n",
    "        sexpression_loss = paddle.sum(paddle.pow(paddle.subtract(latent, expression), 2.0))\n",
    "        coef_constraint = paddle.sum(paddle.pow(GAESC.coefficient, 2))\n",
    "        reconstruct_loss = ce_loss(paddle.nn.Sigmoid()(paddle.matmul(expression, expression.T)), view_graph.adj_mat[index])\n",
    "        loss = loss + reconstruct_loss / 1229 + sexpression_loss\n",
    "    loss = loss + coef_constraint\n",
    "    if i %50 ==0:\n",
    "        print(\"loss\", loss , sexpression_loss , coef_constraint, reconstruct_loss)\n",
    "    loss.backward()\n",
    "    opt_AE.step()\n",
    "    opt_AE.clear_grad()\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epoch_num)):\n",
    "    # process all graph from single view\n",
    "    loss = 0\n",
    "    expression_list = list()\n",
    "    if epoch % 100 == 0:\n",
    "        coeff_cluster_label = GAESC.Ncut_clustering()\n",
    "        with open(\"label.txt\", \"a\") as f:\n",
    "            print(coeff_cluster_label, file=f)\n",
    "    for index in range(len(view_origin)):\n",
    "        # calculate all loss, \"Reconstruct Loss\" :cross-entropy loss first\n",
    "        latent, expression, label = GAESC(view_origin[index], index)\n",
    "\n",
    "        # GAESC.coefficient = GAESC.coefficient / paddle.max(paddle.abs(GAESC.coefficient))\n",
    "\n",
    "        reconstruct_loss = ce_loss(paddle.nn.Sigmoid()(paddle.matmul(expression, expression.T)), view_graph.adj_mat[index])\n",
    "        # reconstruct_loss = ce_loss(pretext_label, view_graph.similarityMat[index].astype(\"float32\"))\n",
    "\n",
    "        sexpression_loss = paddle.linalg.norm(paddle.subtract(latent, expression)) ** 2\n",
    "\n",
    "        expression_list.append(expression)\n",
    "\n",
    "        # diag_constraint = paddle.sum(paddle.square(paddle.sum(paddle.abs(GAESC.coefficient), axis=0)))\n",
    "        # diag_constraint = paddle.linalg.norm(GAESC.coefficient) ** 2\n",
    "        diag_constraint = paddle.pow(GAESC.coefficient)\n",
    "\n",
    "        supervision_constraint_part1 = ce_loss(label, paddle.nn.functional.one_hot(paddle.to_tensor(coeff_cluster_label, dtype=\"int32\"), label.shape[1]))\n",
    "        # supervision_constraint_part2 = center_loss()\n",
    "        supervision_constraint = supervision_constraint_part1# + supervision_constraint_part2\n",
    "        supervision_SExpression_loss = utils.supervision_SExpression(coeff_cluster_label, GAESC.coefficient)\n",
    "        loss = loss + reconstruct_loss + sexpression_loss + diag_constraint + supervision_SExpression_loss + supervision_constraint\n",
    "    loss = loss + utils.consistent_constraint(expression_list)\n",
    "    print(\"Loss: \", loss, reconstruct_loss , sexpression_loss , diag_constraint , supervision_SExpression_loss , supervision_constraint)\n",
    "    loss.backward()\n",
    "    iter_epoch.append(epoch)\n",
    "    history_loss.append(loss.numpy()[0])\n",
    "    opt.step()\n",
    "    opt.clear_grad()\n",
    "        \n",
    "plt.plot(iter_epoch,history_loss, label = 'loss')\n",
    "plt.legend()\n",
    "plt.xlabel('iters')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "paddle.save(GAESC.state_dict(),'model')\n",
    "print(\"model saved success.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# define a random dataset\n",
    "class myDataset(paddle.io.Dataset):\n",
    "    def __init__(self, data, num_samples):\n",
    "        self.data = data\n",
    "        self.num_samples = num_samples\n",
    "        self.data = paddle.to_tensor(self.transform(data), dtype='float32')\n",
    "\n",
    "    def transform(self, data):\n",
    "        dataset = data.values\n",
    "        return dataset      \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = paddle.unsqueeze(self.data[:, idx], axis=0)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "train_data = myDataset(data[0], data[0].shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epoch_num = 200\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "def train(train_dataset, batch_size):\n",
    "    print('训练开始')\n",
    "    # 实例化模型\n",
    "    model = AutoEncoder(num_sample=batch_size)\n",
    "    # 将模型转换为训练模式\n",
    "    model.train()\n",
    "    # 设置优化器，学习率，并且把模型参数给优化器\n",
    "    opt = paddle.optimizer.Adam(learning_rate=learning_rate,parameters=model.parameters())\n",
    "    # 设置损失函数\n",
    "    mse_loss = paddle.nn.MSELoss()\n",
    "    # 设置数据读取器\n",
    "    data_reader = paddle.io.DataLoader(train_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        # num_workers=4,\n",
    "                        shuffle=False,\n",
    "                        drop_last=False)\n",
    "    history_loss = []\n",
    "    iter_epoch = []\n",
    "    for epoch in tqdm.tqdm(range(epoch_num)):\n",
    "        for batch_id, data in enumerate(data_reader()):             \n",
    "            x = data\n",
    "            print(data)\n",
    "            out = model(x)\n",
    "            avg_loss = mse_loss(out, x)   \n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "        iter_epoch.append(epoch)\n",
    "        history_loss.append(avg_loss.numpy()[0])\n",
    "    # 绘制loss\n",
    "    plt.plot(iter_epoch,history_loss, label = 'loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('iters')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    # 保存模型参数\n",
    "    paddle.save(model.state_dict(),'model')\n",
    "\n",
    "\n",
    "train(train_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pgl\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from pgl.utils.logger import log\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "from paddle.optimizer import Adam\n",
    "\n",
    "\n",
    "class GAT(nn.Layer):\n",
    "    \"\"\"Implement of GAT\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size,\n",
    "            num_class,\n",
    "            num_layers=1,\n",
    "            feat_drop=0.6,\n",
    "            attn_drop=0.6,\n",
    "            num_heads=8,\n",
    "            hidden_size=8, ):\n",
    "        super(GAT, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.num_layers = num_layers\n",
    "        self.feat_drop = feat_drop\n",
    "        self.attn_drop = attn_drop\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gats = nn.LayerList()\n",
    "        for i in range(self.num_layers):\n",
    "            if i == 0:\n",
    "                self.gats.append(\n",
    "                    pgl.nn.GATConv(\n",
    "                        input_size,\n",
    "                        self.hidden_size,\n",
    "                        self.feat_drop,\n",
    "                        self.attn_drop,\n",
    "                        self.num_heads,\n",
    "                        activation='elu'))\n",
    "            elif i == (self.num_layers - 1):\n",
    "                self.gats.append(\n",
    "                    pgl.nn.GATConv(\n",
    "                        self.num_heads * self.hidden_size,\n",
    "                        self.num_class,\n",
    "                        self.feat_drop,\n",
    "                        self.attn_drop,\n",
    "                        1,\n",
    "                        concat=False,\n",
    "                        activation=None))\n",
    "            else:\n",
    "                self.gats.append(\n",
    "                    pgl.nn.GATConv(\n",
    "                        self.num_heads * self.hidden_size,\n",
    "                        self.hidden_size,\n",
    "                        self.feat_drop,\n",
    "                        self.attn_drop,\n",
    "                        self.num_heads,\n",
    "                        activation='elu'))\n",
    "\n",
    "    def forward(self, graph, feature):\n",
    "        for m in self.gats:\n",
    "            feature = m(graph, feature)\n",
    "        print(feature)\n",
    "        return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(feat):\n",
    "    return feat / np.maximum(np.sum(feat, -1, keepdims=True), 1)\n",
    "\n",
    "\n",
    "def load(name, normalized_feature=True):\n",
    "    if name == 'cora':\n",
    "        dataset = pgl.dataset.CoraDataset()\n",
    "    elif name == \"pubmed\":\n",
    "        dataset = pgl.dataset.CitationDataset(\"pubmed\", symmetry_edges=True)\n",
    "    elif name == \"citeseer\":\n",
    "        dataset = pgl.dataset.CitationDataset(\"citeseer\", symmetry_edges=True)\n",
    "    else:\n",
    "        raise ValueError(name + \" dataset doesn't exists\")\n",
    "\n",
    "    indegree = dataset.graph.indegree()\n",
    "    dataset.graph.node_feat[\"words\"] = normalize(dataset.graph.node_feat[\n",
    "        \"words\"])\n",
    "\n",
    "    dataset.graph.tensor()\n",
    "    train_index = dataset.train_index\n",
    "    dataset.train_label = paddle.to_tensor(\n",
    "        np.expand_dims(dataset.y[train_index], -1))\n",
    "    dataset.train_index = paddle.to_tensor(np.expand_dims(train_index, -1))\n",
    "\n",
    "    val_index = dataset.val_index\n",
    "    dataset.val_label = paddle.to_tensor(\n",
    "        np.expand_dims(dataset.y[val_index], -1))\n",
    "    dataset.val_index = paddle.to_tensor(np.expand_dims(val_index, -1))\n",
    "\n",
    "    test_index = dataset.test_index\n",
    "    dataset.test_label = paddle.to_tensor(\n",
    "        np.expand_dims(dataset.y[test_index], -1))\n",
    "    dataset.test_index = paddle.to_tensor(np.expand_dims(test_index, -1))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train(node_index, node_label, gnn_model, graph, criterion, optim):\n",
    "    gnn_model.train()\n",
    "    pred = gnn_model(graph, graph.node_feat[\"words\"])\n",
    "    pred = paddle.gather(pred, node_index)\n",
    "    loss = criterion(pred, node_label)\n",
    "    loss.backward()\n",
    "    acc = paddle.metric.accuracy(input=pred, label=node_label, k=1)\n",
    "    optim.step()\n",
    "    optim.clear_grad()\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "@paddle.no_grad()\n",
    "def eval(node_index, node_label, gnn_model, graph, criterion):\n",
    "    gnn_model.eval()\n",
    "    pred = gnn_model(graph, graph.node_feat[\"words\"])\n",
    "    pred = paddle.gather(pred, node_index)\n",
    "    loss = criterion(pred, node_label)\n",
    "    acc = paddle.metric.accuracy(input=pred, label=node_label, k=1)\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    paddle.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    dataset = load(args.dataset, args.feature_pre_normalize)\n",
    "\n",
    "    graph = dataset.graph\n",
    "    train_index = dataset.train_index\n",
    "    train_label = dataset.train_label\n",
    "\n",
    "    val_index = dataset.val_index\n",
    "    val_label = dataset.val_label\n",
    "\n",
    "    test_index = dataset.test_index\n",
    "    test_label = dataset.test_label\n",
    "    criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "    dur = []\n",
    "\n",
    "    best_test = []\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        cal_val_acc = []\n",
    "        cal_test_acc = []\n",
    "        cal_val_loss = []\n",
    "        cal_test_loss = []\n",
    "        gnn_model = GAT(input_size=graph.node_feat[\"words\"].shape[1],\n",
    "                        num_class=dataset.num_classes,\n",
    "                        num_layers=2,\n",
    "                        feat_drop=0.6,\n",
    "                        attn_drop=0.6,\n",
    "                        num_heads=8,\n",
    "                        hidden_size=8)\n",
    "\n",
    "        optim = Adam(\n",
    "            learning_rate=0.005,\n",
    "            parameters=gnn_model.parameters(),\n",
    "            weight_decay=0.0005)\n",
    "\n",
    "        for epoch in tqdm.tqdm(range(200)):\n",
    "            if epoch >= 3:\n",
    "                start = time.time()\n",
    "            train_loss, train_acc = train(train_index, train_label, gnn_model,\n",
    "                                          graph, criterion, optim)\n",
    "            if epoch >= 3:\n",
    "                end = time.time()\n",
    "                dur.append(end - start)\n",
    "            val_loss, val_acc = eval(val_index, val_label, gnn_model, graph,\n",
    "                                     criterion)\n",
    "            cal_val_acc.append(val_acc.numpy())\n",
    "            cal_val_loss.append(val_loss.numpy())\n",
    "\n",
    "            test_loss, test_acc = eval(test_index, test_label, gnn_model,\n",
    "                                       graph, criterion)\n",
    "            cal_test_acc.append(test_acc.numpy())\n",
    "            cal_test_loss.append(test_loss.numpy())\n",
    "\n",
    "        log.info(\"Runs %s: Model: GAT Best Test Accuracy: %f\" %\n",
    "                 (run, cal_test_acc[np.argmin(cal_val_loss)]))\n",
    "\n",
    "        best_test.append(cal_test_acc[np.argmin(cal_val_loss)])\n",
    "\n",
    "    log.info(\"Average Speed %s sec/ epoch\" % (np.mean(dur)))\n",
    "    log.info(\"Dataset: %s Best Test Accuracy: %f ( stddev: %f )\" %\n",
    "             (args.dataset, np.mean(best_test), np.std(best_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_GAT(args, graph):\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        cal_val_acc = []\n",
    "        cal_test_acc = []\n",
    "        cal_val_loss = []\n",
    "        cal_test_loss = []\n",
    "        gnn_model = GAT(input_size=graph[\"feature\"].shape[1],\n",
    "                        num_class=dataset.num_classes,\n",
    "                        num_layers=2,\n",
    "                        feat_drop=0.6,\n",
    "                        attn_drop=0.6,\n",
    "                        num_heads=8,\n",
    "                        hidden_size=8)\n",
    "\n",
    "        optim = Adam(\n",
    "            learning_rate=0.005,\n",
    "            parameters=gnn_model.parameters(),\n",
    "            weight_decay=0.0005)\n",
    "\n",
    "        for epoch in tqdm.tqdm(range(200)):\n",
    "            if epoch >= 3:\n",
    "                start = time.time()\n",
    "            train_loss, train_acc = train(train_index, train_label, gnn_model,\n",
    "                                          graph, criterion, optim)\n",
    "            if epoch >= 3:\n",
    "                end = time.time()\n",
    "                dur.append(end - start)\n",
    "            val_loss, val_acc = eval(val_index, val_label, gnn_model, graph,\n",
    "                                     criterion)\n",
    "            cal_val_acc.append(val_acc.numpy())\n",
    "            cal_val_loss.append(val_loss.numpy())\n",
    "\n",
    "            test_loss, test_acc = eval(test_index, test_label, gnn_model,\n",
    "                                       graph, criterion)\n",
    "            cal_test_acc.append(test_acc.numpy())\n",
    "            cal_test_loss.append(test_loss.numpy())\n",
    "\n",
    "        log.info(\"Runs %s: Model: GAT Best Test Accuracy: %f\" %\n",
    "                 (run, cal_test_acc[np.argmin(cal_val_loss)]))\n",
    "\n",
    "        best_test.append(cal_test_acc[np.argmin(cal_val_loss)])\n",
    "\n",
    "    log.info(\"Average Speed %s sec/ epoch\" % (np.mean(dur)))\n",
    "    log.info(\"Dataset: %s Best Test Accuracy: %f ( stddev: %f )\" %\n",
    "             (args.dataset, np.mean(best_test), np.std(best_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_trte_data(data_folder, view_list):\n",
    "    num_view = len(view_list)\n",
    "    # how many omics data to fusion\n",
    "    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=',')\n",
    "    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=',')\n",
    "    labels_tr = labels_tr.astype(int)\n",
    "    labels_te = labels_te.astype(int)\n",
    "    data_tr_list = []\n",
    "    data_te_list = []\n",
    "    for i in view_list:\n",
    "        data_tr_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','))\n",
    "        data_te_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_te.csv\"), delimiter=','))\n",
    "    num_tr = data_tr_list[0].shape[0]\n",
    "    num_te = data_te_list[0].shape[0]\n",
    "    data_mat_list = []\n",
    "    for i in range(num_view):\n",
    "        data_mat_list.append(np.concatenate((data_tr_list[i], data_te_list[i]), axis=0))\n",
    "    data_tensor_list = []\n",
    "    for i in range(len(data_mat_list)):\n",
    "        data_tensor_list.append(torch.FloatTensor(data_mat_list[i]))\n",
    "        if cuda:\n",
    "            data_tensor_list[i] = data_tensor_list[i].cuda()\n",
    "    idx_dict = {}\n",
    "    idx_dict[\"tr\"] = list(range(num_tr))\n",
    "    idx_dict[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n",
    "    data_train_list = []\n",
    "    data_all_list = []\n",
    "    for i in range(len(data_tensor_list)):\n",
    "        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n",
    "        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n",
    "                                       data_tensor_list[i][idx_dict[\"te\"]].clone()),0))\n",
    "    labels = np.concatenate((labels_tr, labels_te))\n",
    "    \n",
    "    return data_train_list, data_all_list, idx_dict, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"TCGA/BRCA/count_ENSG.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.drop(\"X1\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def thrC(C,ro):\n",
    "    if ro < 1:\n",
    "        N = C.shape[1]\n",
    "        Cp = np.zeros((N,N))\n",
    "        S = np.abs(np.sort(-np.abs(C),axis=0))\n",
    "        \n",
    "        Ind = np.argsort(-np.abs(C),axis=0)\n",
    "\n",
    "        print(f's:{S}, \\nInd:{Ind}')\n",
    "\n",
    "        for i in range(N):\n",
    "            cL1 = np.sum(S[:,i]).astype(float)\n",
    "            stop = False\n",
    "            csum = 0\n",
    "            t = 0\n",
    "            while(stop == False):\n",
    "                csum = csum + S[t,i]\n",
    "                if csum > ro*cL1:\n",
    "                    stop = True\n",
    "                    Cp[Ind[0:t+1,i],i] = C[Ind[0:t+1,i],i]\n",
    "                    # print(f\"cp:{Cp}\")\n",
    "                t = t + 1\n",
    "    else:\n",
    "        Cp = C\n",
    "\n",
    "    return Cp\n",
    "c = np.random.random([10,10])\n",
    "print(c)\n",
    "pro_c = thrC(c, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn import cluster\n",
    "from sklearn.preprocessing import normalize\n",
    "def post_proC(C, K, d, alpha):\n",
    "    # C: coefficient matrix, K: number of clusters, d: dimension of each subspace\n",
    "    C = 0.5*(C + C.T)\n",
    "    r = d*K + 1\n",
    "    U, S, _ = svds(C,r,v0 = np.ones(C.shape[0]))\n",
    "    U = U[:,::-1]    \n",
    "    S = np.sqrt(S[::-1])\n",
    "    S = np.diag(S)    \n",
    "    U = U.dot(S)    \n",
    "    U = normalize(U, norm='l2', axis = 1)       \n",
    "    Z = U.dot(U.T)\n",
    "    Z = Z * (Z>0) \n",
    "\n",
    "    L = np.abs(Z ** alpha)\n",
    "    L = L/L.max()\n",
    "    L = 0.5 * (L + L.T)    \n",
    "\n",
    "    spectral = cluster.SpectralClustering(n_clusters=K, eigen_solver='arpack', affinity='precomputed',assign_labels='discretize')\n",
    "    spectral.fit(L)\n",
    "    grp = spectral.fit_predict(L) + 1\n",
    "    return grp, L\n",
    "\n",
    "x, L = post_proC(pro_c, 2, 4, 3.5)\n",
    "import pandas as pd\n",
    "pd.DataFrame(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! python work/dataloader_tcga.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "mirna = pd.read_csv(os.path.join(\"TCGA/bic/\", \"exp\"), sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "class Model(paddle.nn.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        saved_tensor = self.create_tensor(name=\"saved_tensor0\")\n",
    "        self.register_buffer(\"saved_tensor\", saved_tensor, persistable=True)\n",
    "        self.flatten = paddle.nn.Flatten()\n",
    "        self.fc = paddle.nn.Linear(10, 100)\n",
    "\n",
    "    def forward(self, input):\n",
    "        y = self.flatten(input)\n",
    "        # Save intermediate tensor\n",
    "        paddle.assign(y, self.saved_tensor)\n",
    "        y = self.fc(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "# paddle.enable_static\n",
    "model = Model()\n",
    "print(model.buffers())\n",
    "for item in model.named_buffers():\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.optimizer import Adam\n",
    "import pgl\n",
    "\n",
    "\n",
    "def build_graph():\n",
    "    # define the number of nodes; we can use number to represent every node\n",
    "    num_node = 10\n",
    "    # add edges, we represent all edges as a list of tuple (src, dst)\n",
    "    edge_list = [(2, 0), (2, 1), (3, 1),(4, 0), (5, 0), \n",
    "             (6, 0), (6, 4), (6, 5), (7, 0), (7, 1),\n",
    "             (7, 2), (7, 3), (8, 0), (9, 7)]\n",
    "\n",
    "    # Each node can be represented by a d-dimensional feature vector, here for simple, the feature vectors are randomly generated.\n",
    "    d = 16\n",
    "    feature = np.random.randn(3,num_node, d).astype(\"float32\")\n",
    "    # each edge has it own weight\n",
    "    edge_feature = np.random.randn(len(edge_list), 1).astype(\"float32\")\n",
    "    \n",
    "    # create a graph\n",
    "    g = pgl.Graph(edges = edge_list,\n",
    "                  num_nodes = num_node,\n",
    "                  node_feat = {'nfeat':feature}, \n",
    "                  edge_feat ={'efeat': edge_feature})\n",
    "\n",
    "    return g\n",
    "g = build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T17:00:08.815057Z",
     "iopub.status.busy": "2022-06-08T17:00:08.814580Z",
     "iopub.status.idle": "2022-06-08T17:00:08.857176Z",
     "shell.execute_reply": "2022-06-08T17:00:08.856584Z",
     "shell.execute_reply.started": "2022-06-08T17:00:08.815019Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA.3L.AA1B.01</th>\n",
       "      <th>TCGA.4N.A93T.01</th>\n",
       "      <th>TCGA.4T.AA8H.01</th>\n",
       "      <th>TCGA.5M.AAT4.01</th>\n",
       "      <th>TCGA.5M.AAT6.01</th>\n",
       "      <th>TCGA.5M.AATE.01</th>\n",
       "      <th>TCGA.A6.2670.01</th>\n",
       "      <th>TCGA.A6.2671.01</th>\n",
       "      <th>TCGA.A6.2672.01</th>\n",
       "      <th>TCGA.A6.2674.01</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA.QG.A5YV.01</th>\n",
       "      <th>TCGA.QG.A5YW.01</th>\n",
       "      <th>TCGA.QG.A5YX.01</th>\n",
       "      <th>TCGA.QG.A5Z1.01</th>\n",
       "      <th>TCGA.QG.A5Z2.01</th>\n",
       "      <th>TCGA.QL.A97D.01</th>\n",
       "      <th>TCGA.RU.A8FL.01</th>\n",
       "      <th>TCGA.SS.A7HO.01</th>\n",
       "      <th>TCGA.T9.A92H.01</th>\n",
       "      <th>TCGA.WS.AB45.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>?|100130426</th>\n",
       "      <td>0.5174</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|100133144</th>\n",
       "      <td>18.0851</td>\n",
       "      <td>4.4315</td>\n",
       "      <td>9.8995</td>\n",
       "      <td>7.9174</td>\n",
       "      <td>3.9637</td>\n",
       "      <td>11.6290</td>\n",
       "      <td>11.082847</td>\n",
       "      <td>11.082847</td>\n",
       "      <td>11.082847</td>\n",
       "      <td>11.082847</td>\n",
       "      <td>...</td>\n",
       "      <td>11.3825</td>\n",
       "      <td>13.4798</td>\n",
       "      <td>14.7995</td>\n",
       "      <td>14.8599</td>\n",
       "      <td>23.6064</td>\n",
       "      <td>15.6590</td>\n",
       "      <td>15.8447</td>\n",
       "      <td>24.4956</td>\n",
       "      <td>9.3690</td>\n",
       "      <td>3.9827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|100134869</th>\n",
       "      <td>15.7640</td>\n",
       "      <td>4.2767</td>\n",
       "      <td>11.3032</td>\n",
       "      <td>18.7608</td>\n",
       "      <td>15.0672</td>\n",
       "      <td>6.9060</td>\n",
       "      <td>8.748315</td>\n",
       "      <td>8.748315</td>\n",
       "      <td>8.748315</td>\n",
       "      <td>8.748315</td>\n",
       "      <td>...</td>\n",
       "      <td>11.8390</td>\n",
       "      <td>12.4813</td>\n",
       "      <td>7.2954</td>\n",
       "      <td>14.7523</td>\n",
       "      <td>8.6184</td>\n",
       "      <td>4.6528</td>\n",
       "      <td>11.8574</td>\n",
       "      <td>16.4102</td>\n",
       "      <td>7.8797</td>\n",
       "      <td>4.4654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|10357</th>\n",
       "      <td>144.4004</td>\n",
       "      <td>142.6609</td>\n",
       "      <td>143.1987</td>\n",
       "      <td>146.1876</td>\n",
       "      <td>228.2519</td>\n",
       "      <td>240.7145</td>\n",
       "      <td>218.667527</td>\n",
       "      <td>218.667527</td>\n",
       "      <td>218.667527</td>\n",
       "      <td>218.667527</td>\n",
       "      <td>...</td>\n",
       "      <td>345.5358</td>\n",
       "      <td>144.8068</td>\n",
       "      <td>224.0507</td>\n",
       "      <td>247.3256</td>\n",
       "      <td>136.5238</td>\n",
       "      <td>321.6391</td>\n",
       "      <td>304.8002</td>\n",
       "      <td>263.5938</td>\n",
       "      <td>215.6332</td>\n",
       "      <td>105.0739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|10431</th>\n",
       "      <td>774.6615</td>\n",
       "      <td>1185.2927</td>\n",
       "      <td>888.3202</td>\n",
       "      <td>1280.5508</td>\n",
       "      <td>945.6358</td>\n",
       "      <td>606.8490</td>\n",
       "      <td>963.474022</td>\n",
       "      <td>963.474022</td>\n",
       "      <td>963.474022</td>\n",
       "      <td>963.474022</td>\n",
       "      <td>...</td>\n",
       "      <td>961.9207</td>\n",
       "      <td>1296.0559</td>\n",
       "      <td>1061.7840</td>\n",
       "      <td>562.6314</td>\n",
       "      <td>790.1954</td>\n",
       "      <td>964.5725</td>\n",
       "      <td>1007.2661</td>\n",
       "      <td>738.9138</td>\n",
       "      <td>1445.0989</td>\n",
       "      <td>397.4616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYX|7791</th>\n",
       "      <td>6259.1876</td>\n",
       "      <td>4653.1205</td>\n",
       "      <td>4460.6105</td>\n",
       "      <td>4190.1893</td>\n",
       "      <td>6165.9916</td>\n",
       "      <td>5513.8137</td>\n",
       "      <td>4828.840499</td>\n",
       "      <td>4828.840499</td>\n",
       "      <td>4828.840499</td>\n",
       "      <td>4828.840499</td>\n",
       "      <td>...</td>\n",
       "      <td>3783.1349</td>\n",
       "      <td>4591.9121</td>\n",
       "      <td>2604.3372</td>\n",
       "      <td>4343.2321</td>\n",
       "      <td>3495.7148</td>\n",
       "      <td>4794.5205</td>\n",
       "      <td>4297.0027</td>\n",
       "      <td>1927.7905</td>\n",
       "      <td>4669.3311</td>\n",
       "      <td>8390.9445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZEF1|23140</th>\n",
       "      <td>1358.3172</td>\n",
       "      <td>1220.1258</td>\n",
       "      <td>3002.0106</td>\n",
       "      <td>1093.3735</td>\n",
       "      <td>1390.5637</td>\n",
       "      <td>733.1615</td>\n",
       "      <td>1791.462566</td>\n",
       "      <td>1791.462566</td>\n",
       "      <td>1791.462566</td>\n",
       "      <td>1791.462566</td>\n",
       "      <td>...</td>\n",
       "      <td>850.1427</td>\n",
       "      <td>933.7993</td>\n",
       "      <td>1227.0867</td>\n",
       "      <td>1233.9531</td>\n",
       "      <td>2500.5142</td>\n",
       "      <td>2176.6651</td>\n",
       "      <td>788.8283</td>\n",
       "      <td>903.8422</td>\n",
       "      <td>974.3374</td>\n",
       "      <td>2163.9127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZZ3|26009</th>\n",
       "      <td>798.3559</td>\n",
       "      <td>333.8171</td>\n",
       "      <td>530.0676</td>\n",
       "      <td>574.4406</td>\n",
       "      <td>717.2657</td>\n",
       "      <td>586.9411</td>\n",
       "      <td>654.676705</td>\n",
       "      <td>654.676705</td>\n",
       "      <td>654.676705</td>\n",
       "      <td>654.676705</td>\n",
       "      <td>...</td>\n",
       "      <td>613.5983</td>\n",
       "      <td>590.3145</td>\n",
       "      <td>631.3421</td>\n",
       "      <td>1016.2362</td>\n",
       "      <td>796.0233</td>\n",
       "      <td>598.4884</td>\n",
       "      <td>789.7366</td>\n",
       "      <td>688.4345</td>\n",
       "      <td>508.2036</td>\n",
       "      <td>720.4996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psiTPTE22|387590</th>\n",
       "      <td>13.0561</td>\n",
       "      <td>1.9352</td>\n",
       "      <td>2.1934</td>\n",
       "      <td>6.4544</td>\n",
       "      <td>255.9320</td>\n",
       "      <td>5.4918</td>\n",
       "      <td>29.385028</td>\n",
       "      <td>29.385028</td>\n",
       "      <td>29.385028</td>\n",
       "      <td>29.385028</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9358</td>\n",
       "      <td>21.5676</td>\n",
       "      <td>12.2750</td>\n",
       "      <td>5.3840</td>\n",
       "      <td>6.5135</td>\n",
       "      <td>5.1960</td>\n",
       "      <td>2.7248</td>\n",
       "      <td>6.9627</td>\n",
       "      <td>5.0484</td>\n",
       "      <td>80.8601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tAKR|389932</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20531 rows × 444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TCGA.3L.AA1B.01  TCGA.4N.A93T.01  TCGA.4T.AA8H.01  \\\n",
       "?|100130426                0.5174           0.0000           0.0000   \n",
       "?|100133144               18.0851           4.4315           9.8995   \n",
       "?|100134869               15.7640           4.2767          11.3032   \n",
       "?|10357                  144.4004         142.6609         143.1987   \n",
       "?|10431                  774.6615        1185.2927         888.3202   \n",
       "...                           ...              ...              ...   \n",
       "ZYX|7791                6259.1876        4653.1205        4460.6105   \n",
       "ZZEF1|23140             1358.3172        1220.1258        3002.0106   \n",
       "ZZZ3|26009               798.3559         333.8171         530.0676   \n",
       "psiTPTE22|387590          13.0561           1.9352           2.1934   \n",
       "tAKR|389932                0.0000           0.9676           0.0000   \n",
       "\n",
       "                  TCGA.5M.AAT4.01  TCGA.5M.AAT6.01  TCGA.5M.AATE.01  \\\n",
       "?|100130426                0.0000           0.0000           0.0000   \n",
       "?|100133144                7.9174           3.9637          11.6290   \n",
       "?|100134869               18.7608          15.0672           6.9060   \n",
       "?|10357                  146.1876         228.2519         240.7145   \n",
       "?|10431                 1280.5508         945.6358         606.8490   \n",
       "...                           ...              ...              ...   \n",
       "ZYX|7791                4190.1893        6165.9916        5513.8137   \n",
       "ZZEF1|23140             1093.3735        1390.5637         733.1615   \n",
       "ZZZ3|26009               574.4406         717.2657         586.9411   \n",
       "psiTPTE22|387590           6.4544         255.9320           5.4918   \n",
       "tAKR|389932                0.4303           0.6562           0.0000   \n",
       "\n",
       "                  TCGA.A6.2670.01  TCGA.A6.2671.01  TCGA.A6.2672.01  \\\n",
       "?|100130426              0.025573         0.025573         0.025573   \n",
       "?|100133144             11.082847        11.082847        11.082847   \n",
       "?|100134869              8.748315         8.748315         8.748315   \n",
       "?|10357                218.667527       218.667527       218.667527   \n",
       "?|10431                963.474022       963.474022       963.474022   \n",
       "...                           ...              ...              ...   \n",
       "ZYX|7791              4828.840499      4828.840499      4828.840499   \n",
       "ZZEF1|23140           1791.462566      1791.462566      1791.462566   \n",
       "ZZZ3|26009             654.676705       654.676705       654.676705   \n",
       "psiTPTE22|387590        29.385028        29.385028        29.385028   \n",
       "tAKR|389932              0.041774         0.041774         0.041774   \n",
       "\n",
       "                  TCGA.A6.2674.01  ...  TCGA.QG.A5YV.01  TCGA.QG.A5YW.01  \\\n",
       "?|100130426              0.025573  ...           0.0000           0.0000   \n",
       "?|100133144             11.082847  ...          11.3825          13.4798   \n",
       "?|100134869              8.748315  ...          11.8390          12.4813   \n",
       "?|10357                218.667527  ...         345.5358         144.8068   \n",
       "?|10431                963.474022  ...         961.9207        1296.0559   \n",
       "...                           ...  ...              ...              ...   \n",
       "ZYX|7791              4828.840499  ...        3783.1349        4591.9121   \n",
       "ZZEF1|23140           1791.462566  ...         850.1427         933.7993   \n",
       "ZZZ3|26009             654.676705  ...         613.5983         590.3145   \n",
       "psiTPTE22|387590        29.385028  ...           3.9358          21.5676   \n",
       "tAKR|389932              0.041774  ...           0.0000           0.3994   \n",
       "\n",
       "                  TCGA.QG.A5YX.01  TCGA.QG.A5Z1.01  TCGA.QG.A5Z2.01  \\\n",
       "?|100130426                0.0000           0.0000           0.0000   \n",
       "?|100133144               14.7995          14.8599          23.6064   \n",
       "?|100134869                7.2954          14.7523           8.6184   \n",
       "?|10357                  224.0507         247.3256         136.5238   \n",
       "?|10431                 1061.7840         562.6314         790.1954   \n",
       "...                           ...              ...              ...   \n",
       "ZYX|7791                2604.3372        4343.2321        3495.7148   \n",
       "ZZEF1|23140             1227.0867        1233.9531        2500.5142   \n",
       "ZZZ3|26009               631.3421        1016.2362         796.0233   \n",
       "psiTPTE22|387590          12.2750           5.3840           6.5135   \n",
       "tAKR|389932                0.0000           0.0000           0.0000   \n",
       "\n",
       "                  TCGA.QL.A97D.01  TCGA.RU.A8FL.01  TCGA.SS.A7HO.01  \\\n",
       "?|100130426                0.0000           0.0000           0.0000   \n",
       "?|100133144               15.6590          15.8447          24.4956   \n",
       "?|100134869                4.6528          11.8574          16.4102   \n",
       "?|10357                  321.6391         304.8002         263.5938   \n",
       "?|10431                  964.5725        1007.2661         738.9138   \n",
       "...                           ...              ...              ...   \n",
       "ZYX|7791                4794.5205        4297.0027        1927.7905   \n",
       "ZZEF1|23140             2176.6651         788.8283         903.8422   \n",
       "ZZZ3|26009               598.4884         789.7366         688.4345   \n",
       "psiTPTE22|387590           5.1960           2.7248           6.9627   \n",
       "tAKR|389932                0.0000           0.9083           0.0000   \n",
       "\n",
       "                  TCGA.T9.A92H.01  TCGA.WS.AB45.01  \n",
       "?|100130426                0.0000           0.0000  \n",
       "?|100133144                9.3690           3.9827  \n",
       "?|100134869                7.8797           4.4654  \n",
       "?|10357                  215.6332         105.0739  \n",
       "?|10431                 1445.0989         397.4616  \n",
       "...                           ...              ...  \n",
       "ZYX|7791                4669.3311        8390.9445  \n",
       "ZZEF1|23140              974.3374        2163.9127  \n",
       "ZZZ3|26009               508.2036         720.4996  \n",
       "psiTPTE22|387590           5.0484          80.8601  \n",
       "tAKR|389932                0.0000           0.0000  \n",
       "\n",
       "[20531 rows x 444 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
